# Ã‰tude de Cas ERD â€” Niveau Senior

## Guide de PrÃ©paration aux Examens : Architectures Complexes et Optimisation AvancÃ©e

---

Ce document senior vous prÃ©pare Ã  concevoir des ERD pour des systÃ¨mes bancaires Ã  grande Ã©chelle, avec des millions de transactions, des contraintes de haute disponibilitÃ©, et des besoins de performance extrÃªmes. Vous apprendrez Ã  faire des compromis architecturaux justifiÃ©s.

---

## ğŸ¯ Concepts d'architecture couverts

- DÃ©normalisation stratÃ©gique et trade-offs
- Partitionnement horizontal et vertical
- RÃ©plication et stratÃ©gies de cohÃ©rence
- Event Sourcing et CQRS
- Sharding et distribution gÃ©ographique
- Audit trail et conformitÃ© (SOX, GDPR)
- Temporal tables et time-travel queries

---

## ProblÃ¨me 1 : DÃ©normalisation StratÃ©gique - Table de Reporting

### Contexte

Vous gÃ©rez 10 millions de transactions par jour. Le rapport quotidien suivant prend 45 secondes Ã  gÃ©nÃ©rer :

```sql
SELECT 
    c.client_id,
    c.nom,
    COUNT(t.transaction_id) AS nb_transactions,
    SUM(CASE WHEN t.type_tx = 'DEPOT' THEN t.montant ELSE 0 END) AS total_depots,
    SUM(CASE WHEN t.type_tx = 'RETRAIT' THEN t.montant ELSE 0 END) AS total_retraits,
    SUM(co.solde) AS solde_total
FROM clients c
LEFT JOIN comptes co ON co.client_id = c.client_id
LEFT JOIN transactions t ON t.compte_id = co.compte_id
WHERE t.date_tx >= CURRENT_DATE - INTERVAL 30 DAYS
GROUP BY c.client_id, c.nom;
```

### Solution - Table dÃ©normalisÃ©e avec mise Ã  jour incrÃ©mentale

#### ERD NormalisÃ© vs DÃ©normalisÃ©

```
=== MODÃˆLE NORMALISÃ‰ (actuel) ===

CLIENT â”€â”¤â”œâ”€â”€â”€â”€â—‹< COMPTE â”€â”¤â”œâ”€â”€â”€â”€â—‹< TRANSACTION
(3 JOINs pour chaque rapport)


=== MODÃˆLE DÃ‰NORMALISÃ‰ (optimisÃ©) ===

CLIENT â”€â”¤â”œâ”€â”€â”€â”€â—‹< COMPTE â”€â”¤â”œâ”€â”€â”€â”€â—‹< TRANSACTION
   â”‚
   â”‚
   â””â”€â”€â”€â”€â”¤â”œâ”€â”€â”€â”€ STATS_CLIENT_30J  (table matÃ©rialisÃ©e, rafraÃ®chie par trigger)
             â”œâ”€ client_id (PK, FK)
             â”œâ”€ nb_transactions
             â”œâ”€ total_depots
             â”œâ”€ total_retraits
             â”œâ”€ solde_total
             â””â”€ date_maj
```

#### SQL - Table dÃ©normalisÃ©e

```sql
CREATE TABLE stats_clients_30j (
    client_id       INT PRIMARY KEY,
    nb_transactions INT DEFAULT 0,
    total_depots    DECIMAL(15,2) DEFAULT 0,
    total_retraits  DECIMAL(15,2) DEFAULT 0,
    solde_total     DECIMAL(15,2) DEFAULT 0,
    date_maj        TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,
    FOREIGN KEY (client_id) REFERENCES clients(client_id)
);

-- Index pour requÃªtes de filtrage
CREATE INDEX idx_stats_depots ON stats_clients_30j(total_depots);
CREATE INDEX idx_stats_solde ON stats_clients_30j(solde_total);

-- Trigger de mise Ã  jour incrÃ©mentale
DELIMITER $$
CREATE TRIGGER trg_maj_stats_transaction
AFTER INSERT ON transactions
FOR EACH ROW
BEGIN
    DECLARE v_client_id INT;
    
    -- RÃ©cupÃ©rer le client_id du compte
    SELECT client_id INTO v_client_id
    FROM comptes
    WHERE compte_id = NEW.compte_id;
    
    -- Mise Ã  jour incrÃ©mentale des stats
    INSERT INTO stats_clients_30j (client_id, nb_transactions, total_depots, total_retraits)
    VALUES (
        v_client_id,
        1,
        IF(NEW.type_tx = 'DEPOT', NEW.montant, 0),
        IF(NEW.type_tx = 'RETRAIT', NEW.montant, 0)
    )
    ON DUPLICATE KEY UPDATE
        nb_transactions = nb_transactions + 1,
        total_depots = total_depots + IF(NEW.type_tx = 'DEPOT', NEW.montant, 0),
        total_retraits = total_retraits + IF(NEW.type_tx = 'RETRAIT', NEW.montant, 0);
END$$
DELIMITER ;

-- Job de recalcul quotidien (pour correction de dÃ©rives)
-- Ã€ exÃ©cuter via cron ou scheduler DB
TRUNCATE TABLE stats_clients_30j;
INSERT INTO stats_clients_30j (client_id, nb_transactions, total_depots, total_retraits, solde_total)
SELECT 
    c.client_id,
    COUNT(t.transaction_id),
    SUM(CASE WHEN t.type_tx = 'DEPOT' THEN t.montant ELSE 0 END),
    SUM(CASE WHEN t.type_tx = 'RETRAIT' THEN t.montant ELSE 0 END),
    SUM(co.solde)
FROM clients c
LEFT JOIN comptes co ON co.client_id = c.client_id
LEFT JOIN transactions t ON t.compte_id = co.compte_id AND t.date_tx >= CURRENT_DATE - INTERVAL 30 DAYS
GROUP BY c.client_id;
```

#### Trade-offs

| Aspect | Avant (3NF pur) | AprÃ¨s (DÃ©normalisÃ©) |
|--------|-----------------|---------------------|
| **Performance lecture** | 45s (JOINs lourds) | < 100ms (lecture directe) |
| **Performance Ã©criture** | Rapide (INSERT simple) | LÃ©gÃ¨rement plus lent (trigger) |
| **Stockage** | Optimal | +2-5% (table stats) |
| **Risque d'incohÃ©rence** | ZÃ©ro | Faible (job de correction) |
| **ComplexitÃ©** | Simple | Moyenne (triggers, jobs) |

**RÃ¨gle d'or** : DÃ©normaliser uniquement si le ratio lecture/Ã©criture > 100:1 et la performance est critique.

---

## ProblÃ¨me 2 : Partitionnement Horizontal - Transactions par Date

### Contexte

La table `transactions` contient 500 millions de lignes. Les requÃªtes rÃ©centes sont rapides, mais les recherches historiques sont lentes. 90% des requÃªtes concernent les 3 derniers mois.

### Solution - Partitionnement par RANGE sur date_transaction

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚             TRANSACTION (logique)               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ PK transaction_id                               â”‚
â”‚ FK compte_id                                    â”‚
â”‚    date_transaction [PARTITION KEY]             â”‚
â”‚    montant                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â”‚ (Partitionnement physique)
         â”‚
    â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚               â”‚              â”‚              â”‚
â”Œâ”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ tx_2024_01 â”‚ â”‚ tx_2024_02 â”‚ â”‚ tx_2024_03 â”‚ â”‚ tx_2024_04... â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
(Janvier)      (FÃ©vrier)      (Mars)         (Archives)
```

### SQL - Partitionnement MySQL

```sql
CREATE TABLE transactions (
    transaction_id      BIGINT AUTO_INCREMENT,
    compte_id           INT NOT NULL,
    type_tx             VARCHAR(10) NOT NULL,
    montant             DECIMAL(12,2) NOT NULL,
    date_transaction    DATE NOT NULL,
    description         TEXT,
    INDEX idx_compte (compte_id),
    INDEX idx_date (date_transaction),
    PRIMARY KEY (transaction_id, date_transaction)
)
PARTITION BY RANGE (YEAR(date_transaction) * 100 + MONTH(date_transaction)) (
    PARTITION p_2024_01 VALUES LESS THAN (202402),
    PARTITION p_2024_02 VALUES LESS THAN (202403),
    PARTITION p_2024_03 VALUES LESS THAN (202404),
    PARTITION p_2024_04 VALUES LESS THAN (202405),
    PARTITION p_2024_05 VALUES LESS THAN (202406),
    PARTITION p_2024_06 VALUES LESS THAN (202407),
    PARTITION p_2024_07 VALUES LESS THAN (202408),
    PARTITION p_2024_08 VALUES LESS THAN (202409),
    PARTITION p_2024_09 VALUES LESS THAN (202410),
    PARTITION p_2024_10 VALUES LESS THAN (202411),
    PARTITION p_2024_11 VALUES LESS THAN (202412),
    PARTITION p_2024_12 VALUES LESS THAN (202501),
    PARTITION p_future VALUES LESS THAN MAXVALUE
);

-- Ajouter une partition pour le mois prochain (Ã  automatiser)
ALTER TABLE transactions REORGANIZE PARTITION p_future INTO (
    PARTITION p_2025_01 VALUES LESS THAN (202502),
    PARTITION p_future VALUES LESS THAN MAXVALUE
);

-- Archiver et supprimer les anciennes partitions
ALTER TABLE transactions DROP PARTITION p_2024_01;
```

### Avantages du partitionnement

âœ… **Performance** : RequÃªtes sur 3 derniers mois = scan de 3 partitions seulement  
âœ… **Maintenance** : Archivage/suppression rapide (DROP PARTITION au lieu de DELETE)  
âœ… **ScalabilitÃ©** : Partitions peuvent Ãªtre sur des disques physiques diffÃ©rents  

### RequÃªte optimisÃ©e automatiquement

```sql
-- Cette requÃªte scanne UNIQUEMENT la partition p_2024_03
SELECT * FROM transactions
WHERE date_transaction BETWEEN '2024-03-01' AND '2024-03-31'
AND compte_id = 1234;

EXPLAIN PARTITIONS SELECT ...;
-- RÃ©sultat : partitions: p_2024_03 (1 seule partition scannÃ©e)
```

---

## ProblÃ¨me 3 : Event Sourcing - Audit Trail Immuable

### Contexte

Dans le secteur bancaire, vous DEVEZ conserver un **audit trail immuable** de toutes les opÃ©rations pour conformitÃ© rÃ©glementaire (SOX, PCI-DSS). Le problÃ¨me : les UPDATE/DELETE effacent l'historique.

### Solution - Event Sourcing Pattern

```
=== MODÃˆLE TRADITIONNEL (Ã‰TAT ACTUEL) ===

COMPTE (Ã©tat mutable)
â”œâ”€ compte_id
â”œâ”€ solde (modifiÃ© par UPDATE)
â””â”€ statut (modifiÃ© par UPDATE)


=== MODÃˆLE EVENT SOURCING (Ã‰VÃ‰NEMENTS IMMUABLES) ===

COMPTE_EVENTS (append-only, jamais de UPDATE/DELETE)
â”œâ”€ event_id (PK, auto-increment)
â”œâ”€ compte_id
â”œâ”€ event_type (COMPTE_CREE, DEPOT, RETRAIT, BLOQUE, FERME)
â”œâ”€ montant
â”œâ”€ solde_apres_event
â”œâ”€ metadata (JSON)
â”œâ”€ timestamp
â””â”€ user_id

COMPTE_SNAPSHOTS (Ã©tat reconstituÃ© pÃ©riodiquement)
â”œâ”€ compte_id (PK)
â”œâ”€ solde_actuel
â”œâ”€ statut
â”œâ”€ version (numÃ©ro du dernier event appliquÃ©)
â””â”€ date_maj
```

### ERD Event Sourcing

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   COMPTE_SNAPSHOTS     â”‚ â† Ã‰tat actuel (lecture rapide)
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ PK compte_id           â”‚â”€â”¤â”œâ”€â”€â”€â”€â—‹<â”€â”
â”‚    solde_actuel        â”‚         â”‚
â”‚    statut              â”‚         â”‚
â”‚    version             â”‚         â”‚
â”‚    date_maj            â”‚         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚
                                   â”‚
                       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                       â”‚   COMPTE_EVENTS (append-only)  â”‚
                       â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
                       â”‚ PK event_id                    â”‚
                       â”‚ FK compte_id                   â”‚
                       â”‚    event_type                  â”‚
                       â”‚    montant                     â”‚
                       â”‚    solde_apres                 â”‚
                       â”‚    metadata (JSON)             â”‚
                       â”‚    timestamp                   â”‚
                       â”‚    user_id                     â”‚
                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       PARTITION BY RANGE(timestamp)
```

### SQL

```sql
-- Table des Ã©vÃ©nements (immuable)
CREATE TABLE compte_events (
    event_id        BIGINT PRIMARY KEY AUTO_INCREMENT,
    compte_id       INT NOT NULL,
    event_type      VARCHAR(30) NOT NULL,
    montant         DECIMAL(12,2),
    solde_apres     DECIMAL(12,2) NOT NULL,
    metadata        JSON,
    timestamp       TIMESTAMP(6) DEFAULT CURRENT_TIMESTAMP(6),
    user_id         INT NOT NULL,
    INDEX idx_compte_ts (compte_id, timestamp),
    INDEX idx_timestamp (timestamp)
) PARTITION BY RANGE (UNIX_TIMESTAMP(timestamp)) (
    -- Partitionnement par mois comme prÃ©cÃ©demment
);

-- Table snapshot (Ã©tat actuel)
CREATE TABLE compte_snapshots (
    compte_id       INT PRIMARY KEY,
    solde_actuel    DECIMAL(12,2) NOT NULL,
    statut          VARCHAR(20) NOT NULL,
    version         BIGINT NOT NULL,  -- Dernier event_id appliquÃ©
    date_maj        TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    FOREIGN KEY (compte_id) REFERENCES comptes(compte_id)
);

-- ProcÃ©dure pour crÃ©er un Ã©vÃ©nement
DELIMITER $$
CREATE PROCEDURE enregistrer_depot(
    IN p_compte_id INT,
    IN p_montant DECIMAL(12,2),
    IN p_user_id INT
)
BEGIN
    DECLARE v_solde_actuel DECIMAL(12,2);
    DECLARE v_nouveau_solde DECIMAL(12,2);
    DECLARE v_event_id BIGINT;
    
    START TRANSACTION;
    
    -- RÃ©cupÃ©rer solde actuel avec verrou
    SELECT solde_actuel INTO v_solde_actuel
    FROM compte_snapshots
    WHERE compte_id = p_compte_id
    FOR UPDATE;
    
    SET v_nouveau_solde = v_solde_actuel + p_montant;
    
    -- CrÃ©er l'Ã©vÃ©nement (JAMAIS de UPDATE sur cette table)
    INSERT INTO compte_events (compte_id, event_type, montant, solde_apres, user_id)
    VALUES (p_compte_id, 'DEPOT', p_montant, v_nouveau_solde, p_user_id);
    
    SET v_event_id = LAST_INSERT_ID();
    
    -- Mettre Ã  jour le snapshot
    UPDATE compte_snapshots
    SET solde_actuel = v_nouveau_solde,
        version = v_event_id,
        date_maj = CURRENT_TIMESTAMP
    WHERE compte_id = p_compte_id;
    
    COMMIT;
END$$
DELIMITER ;
```

### RequÃªtes avancÃ©es

```sql
-- 1. Ã‰tat actuel (lecture du snapshot)
SELECT compte_id, solde_actuel, statut
FROM compte_snapshots
WHERE compte_id = 1234;

-- 2. Historique complet d'un compte
SELECT event_id, event_type, montant, solde_apres, timestamp
FROM compte_events
WHERE compte_id = 1234
ORDER BY event_id;

-- 3. Time-travel query : Quel Ã©tait le solde le 15 mars 2024 Ã  14:30 ?
SELECT solde_apres
FROM compte_events
WHERE compte_id = 1234
  AND timestamp <= '2024-03-15 14:30:00'
ORDER BY timestamp DESC
LIMIT 1;

-- 4. Audit : Qui a modifiÃ© ce compte dans les 7 derniers jours ?
SELECT e.event_type, e.montant, e.timestamp, u.nom AS utilisateur
FROM compte_events e
JOIN users u ON u.user_id = e.user_id
WHERE e.compte_id = 1234
  AND e.timestamp >= CURRENT_TIMESTAMP - INTERVAL 7 DAY
ORDER BY e.timestamp DESC;
```

### Avantages Event Sourcing

âœ… **Audit trail parfait** : Tout est tracÃ©, rien n'est perdu  
âœ… **Time-travel** : Reconstruire l'Ã©tat Ã  n'importe quel moment  
âœ… **Debugging** : Rejouer les Ã©vÃ©nements pour reproduire bugs  
âœ… **ConformitÃ©** : SOX, GDPR, PCI-DSS automatiquement satisfaits  
âœ… **Analytics** : Analyser les patterns comportementaux  

âŒ **ComplexitÃ©** : Courbe d'apprentissage Ã©levÃ©e  
âŒ **Stockage** : Croissance continue (nÃ©cessite archivage)  

---

## ProblÃ¨me 4 : CQRS - SÃ©paration Lecture/Ã‰criture

### Contexte

Votre systÃ¨me bancaire a :
- **Transactions** : 50 000/sec en Ã©criture (haute cohÃ©rence requise)
- **Consultations** : 500 000/sec en lecture (tolÃ©rance Ã  1-2 sec de latence)

Le modÃ¨le unique ne peut pas scaler.

### Solution - CQRS (Command Query Responsibility Segregation)

```
=== ARCHITECTURE TRADITIONNELLE ===

         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚   APPLICATION    â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚   BASE UNIQUE    â”‚ â† Goulot d'Ã©tranglement
         â”‚   (Lecture +     â”‚
         â”‚    Ã‰criture)     â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜


=== ARCHITECTURE CQRS ===

         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚   APPLICATION    â”‚
         â””â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
             â”‚         â”‚
    Commands â”‚         â”‚ Queries
    (Write)  â”‚         â”‚ (Read)
             â”‚         â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”     â”Œâ”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ WRITE DB â”‚â”€â”€â”€â”€>â”‚  READ DB      â”‚ â† RÃ©plication async
    â”‚ (Master) â”‚     â”‚  (Replicas)   â”‚    (1-2 sec lag)
    â”‚          â”‚     â”‚  - Replica 1  â”‚
    â”‚ NormalisÃ©â”‚     â”‚  - Replica 2  â”‚
    â”‚ ACID     â”‚     â”‚  - Replica 3  â”‚
    â”‚          â”‚     â”‚  DÃ©normalisÃ©  â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ERD - ModÃ¨les SÃ©parÃ©s

#### Write Model (Base maÃ®tre - NormalisÃ©e)

```
CLIENT â”€â”¤â”œâ”€â”€â”€â—‹< COMPTE â”€â”¤â”œâ”€â”€â”€â—‹< TRANSACTION
(3NF strict, contraintes ACID, triggers)
```

#### Read Model (Replicas - DÃ©normalisÃ©)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   VUE_COMPTE_ENRICHI (matÃ©rialisÃ©e)  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ compte_id                            â”‚
â”‚ client_nom                           â”‚ â† DÃ©normalisÃ©
â”‚ client_email                         â”‚ â† DÃ©normalisÃ©
â”‚ solde_actuel                         â”‚
â”‚ nb_transactions_30j                  â”‚ â† PrÃ©calculÃ©
â”‚ derniere_transaction_date            â”‚ â† PrÃ©calculÃ©
â”‚ statut_compte                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Index sur TOUT (read-optimized)
```

### SQL - Configuration CQRS

```sql
-- ===== BASE WRITE (MASTER) =====
CREATE TABLE transactions (
    transaction_id BIGINT PRIMARY KEY AUTO_INCREMENT,
    compte_id INT NOT NULL,
    type_tx VARCHAR(10) NOT NULL,
    montant DECIMAL(12,2) NOT NULL,
    date_tx TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    FOREIGN KEY (compte_id) REFERENCES comptes(compte_id)
) ENGINE=InnoDB;  -- ACID strict

-- ===== BASE READ (REPLICA) =====
-- ConfigurÃ©e avec rÃ©plication MySQL maÃ®tre-esclave

-- Vue matÃ©rialisÃ©e pour lectures (refresh toutes les 2 secondes)
CREATE TABLE vue_comptes_enrichis (
    compte_id INT PRIMARY KEY,
    client_nom VARCHAR(100),
    client_email VARCHAR(120),
    solde_actuel DECIMAL(12,2),
    nb_transactions_30j INT,
    derniere_transaction_date TIMESTAMP,
    statut VARCHAR(20),
    date_maj TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    INDEX idx_client_nom (client_nom),
    INDEX idx_email (client_email),
    INDEX idx_solde (solde_actuel),
    INDEX idx_statut (statut)
) ENGINE=InnoDB;

-- Job de refresh (toutes les 2 secondes via cron ou scheduler)
TRUNCATE TABLE vue_comptes_enrichis;
INSERT INTO vue_comptes_enrichis
SELECT 
    co.compte_id,
    cl.nom,
    cl.email,
    co.solde,
    (SELECT COUNT(*) FROM transactions t 
     WHERE t.compte_id = co.compte_id 
     AND t.date_tx >= CURRENT_TIMESTAMP - INTERVAL 30 DAY) AS nb_tx_30j,
    (SELECT MAX(date_tx) FROM transactions t WHERE t.compte_id = co.compte_id) AS derniere_tx,
    co.statut
FROM comptes co
JOIN clients cl ON cl.client_id = co.client_id;
```

### Code Application - SÃ©paration des responsabilitÃ©s

```python
# ===== COMMANDES (Ã‰CRITURE) =====
class DepotCommand:
    def execute(self, compte_id, montant):
        with write_db.transaction():  # Connexion MASTER
            compte = write_db.query("SELECT * FROM comptes WHERE compte_id = %s FOR UPDATE", compte_id)
            if not compte:
                raise ComptInexistant()
            
            write_db.execute("""
                INSERT INTO transactions (compte_id, type_tx, montant)
                VALUES (%s, 'DEPOT', %s)
            """, compte_id, montant)
            
            write_db.execute("""
                UPDATE comptes SET solde = solde + %s WHERE compte_id = %s
            """, montant, compte_id)
        # Pas de retour de donnÃ©es (Command pattern)

# ===== REQUÃŠTES (LECTURE) =====
class CompteQueryService:
    def get_compte_details(self, compte_id):
        # Connexion REPLICA (lecture seule)
        return read_db.query_one("""
            SELECT * FROM vue_comptes_enrichis
            WHERE compte_id = %s
        """, compte_id)
    
    def search_comptes_by_client(self, nom_partiel):
        # Index optimisÃ© sur read replica
        return read_db.query("""
            SELECT * FROM vue_comptes_enrichis
            WHERE client_nom LIKE %s
            ORDER BY solde_actuel DESC
            LIMIT 100
        """, f"%{nom_partiel}%")
```

### Trade-offs CQRS

| Aspect | Avantage | InconvÃ©nient |
|--------|----------|--------------|
| **Performance** | Lectures 10-100x plus rapides | CohÃ©rence Ã©ventuelle (lag 1-2s) |
| **ScalabilitÃ©** | Replicas indÃ©pendants | ComplexitÃ© opÃ©rationnelle |
| **CoÃ»t** | Efficace (scaling horizontal) | Plus de serveurs |
| **Maintenance** | Optimisations indÃ©pendantes | Double modÃ¨le Ã  maintenir |

---

## ProblÃ¨me 5 : Sharding GÃ©ographique - Banque Multi-Pays

### Contexte

Votre banque opÃ¨re dans 5 pays. Les clients franÃ§ais ne consultent jamais les comptes haÃ¯tiens, et vice-versa. La latence rÃ©seau cross-continent tue les performances.

### Solution - Sharding par pays (geo-sharding)

```
=== ARCHITECTURE SHARDÃ‰E ===

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚            GLOBAL ROUTING LAYER                     â”‚
â”‚  (DÃ©termine le shard basÃ© sur client_id)           â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚          â”‚          â”‚          â”‚
   â”Œâ”€â”€â”€â–¼â”€â”€â”€â”  â”Œâ”€â”€â–¼â”€â”€â”€â”€â”  â”Œâ”€â”€â–¼â”€â”€â”€â”€â”  â”Œâ”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
   â”‚SHARD  â”‚  â”‚SHARD  â”‚  â”‚SHARD  â”‚  â”‚ SHARD   â”‚
   â”‚FRANCE â”‚  â”‚HAITI  â”‚  â”‚CANADA â”‚  â”‚ USA     â”‚
   â”‚(Paris)â”‚  â”‚(P-a-P)â”‚  â”‚(MTL)  â”‚  â”‚(NYC)    â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
   
   Chaque shard contient TOUTES les tables pour un sous-ensemble de clients
```

### ERD avec Shard Key

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          CLIENT                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ PK client_id [SHARD KEY]       â”‚ â† DÃ©termine le shard
â”‚    pays_code (FR/HT/CA/US)     â”‚ â† DÃ©normalisÃ© pour routing
â”‚    nom                         â”‚
â”‚    email                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

RÃ¨gle de sharding : 
- client_id % 4 = 0 â†’ SHARD_FRANCE
- client_id % 4 = 1 â†’ SHARD_HAITI
- client_id % 4 = 2 â†’ SHARD_CANADA
- client_id % 4 = 3 â†’ SHARD_USA

(En production : sharding par pays_code plus logique)
```

### SQL - Configuration avec Vitess (ou similaire)

```sql
-- ===== SHARD FRANCE (DB shard_fr) =====
CREATE TABLE clients (
    client_id INT PRIMARY KEY,
    pays_code VARCHAR(2) NOT NULL DEFAULT 'FR',
    nom VARCHAR(100) NOT NULL,
    email VARCHAR(120) UNIQUE,
    CHECK (pays_code = 'FR')  -- Contrainte shard
);

CREATE TABLE comptes (
    compte_id INT PRIMARY KEY,
    client_id INT NOT NULL,
    solde DECIMAL(12,2),
    FOREIGN KEY (client_id) REFERENCES clients(client_id)
);

-- ===== SHARD HAITI (DB shard_ht) =====
CREATE TABLE clients (
    client_id INT PRIMARY KEY,
    pays_code VARCHAR(2) NOT NULL DEFAULT 'HT',
    nom VARCHAR(100) NOT NULL,
    email VARCHAR(120) UNIQUE,
    CHECK (pays_code = 'HT')  -- Contrainte shard
);

CREATE TABLE comptes (
    compte_id INT PRIMARY KEY,
    client_id INT NOT NULL,
    solde DECIMAL(12,2),
    FOREIGN KEY (client_id) REFERENCES clients(client_id)
);

-- ... mÃªme structure pour CA et US
```

### Routing Logic (Application Layer)

```python
class ShardRouter:
    SHARDS = {
        'FR': 'mysql://shard-fr.bank.com:3306/bank_fr',
        'HT': 'mysql://shard-ht.bank.com:3306/bank_ht',
        'CA': 'mysql://shard-ca.bank.com:3306/bank_ca',
        'US': 'mysql://shard-us.bank.com:3306/bank_us',
    }
    
    def get_connection(self, client_id):
        """DÃ©termine le shard Ã  partir du client_id"""
        # Option 1 : Query de metadata (centralisÃ©e)
        pays = metadata_db.query_one("SELECT pays_code FROM client_routing WHERE client_id = %s", client_id)
        
        # Option 2 : Hash consistant
        # shard_index = hash(client_id) % 4
        
        return self.SHARDS[pays]
    
    def execute_query(self, client_id, query, params):
        conn = self.get_connection(client_id)
        return conn.execute(query, params)

# Usage
router = ShardRouter()
compte = router.execute_query(
    client_id=12345,
    query="SELECT * FROM comptes WHERE client_id = %s",
    params=[12345]
)
```

### DÃ©fis du Sharding

âŒ **Cross-shard queries** : Impossible de faire un JOIN entre shards  
âŒ **Transactions distribuÃ©es** : 2PC (Two-Phase Commit) lent et complexe  
âŒ **Rebalancing** : Difficile de migrer des donnÃ©es entre shards  
âŒ **Global uniqueness** : ID globaux nÃ©cessitent coordination (Snowflake ID)  

âœ… **Performance** : Latence rÃ©duite (donnÃ©es proches gÃ©ographiquement)  
âœ… **ScalabilitÃ©** : Croissance linÃ©aire  
âœ… **Isolation** : Pannes isolÃ©es par pays  
âœ… **ConformitÃ©** : GDPR (donnÃ©es UE restent en UE)  

---

## ğŸ“ Checklist ERD - Niveau Senior

âœ… **DÃ©normalisation**
- [ ] Trade-offs documentÃ©s (lecture vs Ã©criture vs cohÃ©rence)
- [ ] StratÃ©gie de synchronisation dÃ©finie (triggers, jobs, messaging)
- [ ] MÃ©triques de performance justifiant la dÃ©normalisation

âœ… **Partitionnement**
- [ ] ClÃ© de partition choisie (date, ID, geo)
- [ ] StratÃ©gie d'archivage des anciennes partitions
- [ ] Gestion automatisÃ©e des nouvelles partitions

âœ… **Event Sourcing**
- [ ] Tous les Ã©vÃ©nements mÃ©tier identifiÃ©s
- [ ] StratÃ©gie de snapshot dÃ©finie (frÃ©quence, retention)
- [ ] RequÃªtes time-travel documentÃ©es

âœ… **CQRS**
- [ ] SÃ©paration write/read justifiÃ©e (ratio lecture/Ã©criture)
- [ ] Lag de rÃ©plication acceptable dÃ©fini
- [ ] Vues matÃ©rialisÃ©es optimisÃ©es pour les queries frÃ©quentes

âœ… **Sharding**
- [ ] Shard key choisie (Ã©viter les hot spots)
- [ ] StratÃ©gie cross-shard documentÃ©e
- [ ] Plan de rebalancing dÃ©fini

---

## ğŸ“ Conseils pour l'Examen - Niveau Senior

### Questions typiques d'architecture

**Q : "La table X contient 1 milliard de lignes et les requÃªtes sont lentes. Que faire ?"**

RÃ©ponse structurÃ©e :
1. **Diagnostiquer** : EXPLAIN, index manquants, requÃªtes inefficaces
2. **Optimiser** : Index, rÃ©Ã©criture queries, vues matÃ©rialisÃ©es
3. **Partitionner** : Si donnÃ©es temporelles ou gÃ©ographiques
4. **Sharding** : Si partitionnement insuffisant
5. **DÃ©normaliser** : Si ratio lecture/Ã©criture trÃ¨s Ã©levÃ©

**Q : "Comment garantir l'audit trail complet dans un systÃ¨me bancaire ?"**

RÃ©ponse :
1. **Event Sourcing** : Pas de UPDATE/DELETE, uniquement INSERT
2. **Partition par date** : ImmutabilitÃ© physique (partitions read-only)
3. **Triggers d'audit** : Table `audit_log` pour tout changement
4. **Replication** : Backup continu sur site distant

### Erreurs Ã  Ã©viter

- âŒ DÃ©normaliser sans justification chiffrÃ©e
- âŒ Sharding prÃ©maturÃ© (complexitÃ© > bÃ©nÃ©fice)
- âŒ Oublier les index sur les foreign keys dans tables dÃ©normalisÃ©es
- âŒ Ne pas documenter les trade-offs

### Phrases clÃ©s pour impressionner

- "Dans ce contexte de **haute vÃ©locitÃ© transactionnelle**, je propose un **CQRS pattern** avec rÃ©plication asynchrone."
- "Pour garantir l'**auditabilitÃ© rÃ©glementaire**, j'implÃ©mente un **event sourcing** avec snapshots quotidiens."
- "La **dÃ©normalisation stratÃ©gique** de cette mÃ©trique justifie le trade-off cohÃ©rence Ã©ventuelle, vu le ratio 1000:1 lecture/Ã©criture."
- "Le **sharding gÃ©ographique** rÃ©duit la latence de 300ms Ã  20ms pour 95% des requÃªtes."

---

## ğŸ“š Ressources AvancÃ©es

- **Books** : 
  - "Designing Data-Intensive Applications" (Martin Kleppmann)
  - "Database Internals" (Alex Petrov)
- **Patterns** : 
  - Event Sourcing (Greg Young)
  - CQRS (Martin Fowler)
- **Tools** :
  - Vitess (sharding MySQL)
  - Debezium (CDC - Change Data Capture)
  - TimescaleDB (time-series sur PostgreSQL)

---

**FÃ©licitations !** Vous maÃ®trisez maintenant la modÃ©lisation ERD du niveau basique au senior. Pratiquez sur des cas rÃ©els et justifiez toujours vos choix architecturaux.
