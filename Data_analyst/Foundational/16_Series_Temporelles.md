# Manuel de Pr√©paration: S√©ries Temporelles et Pr√©visions

## Introduction

Les s√©ries temporelles sont des donn√©es collect√©es √† intervalles r√©guliers dans le temps. Dans le secteur bancaire, elles sont essentielles pour la pr√©vision des d√©p√¥ts, la gestion de la liquidit√©, l'analyse des tendances de cr√©dit, et la planification strat√©gique.

---

## Partie 1: Concepts Fondamentaux

### 1.1 D√©finition

**S√©rie temporelle:** S√©quence d'observations ordonn√©es dans le temps.

```
Y‚Çú = f(t) + Œµ‚Çú

O√π:
- Y‚Çú = Valeur observ√©e au temps t
- f(t) = Composante syst√©matique (tendance, saisonnalit√©)
- Œµ‚Çú = Bruit al√©atoire (r√©sidu)
```

**Exemples bancaires:**
- D√©p√¥ts journaliers/mensuels
- Volume de transactions ATM
- Taux de d√©faut trimestriel
- Solde moyen par client

---

### 1.2 Composantes d'une S√©rie Temporelle

```
Y‚Çú = T‚Çú + S‚Çú + C‚Çú + I‚Çú   (Mod√®le Additif)
Y‚Çú = T‚Çú √ó S‚Çú √ó C‚Çú √ó I‚Çú   (Mod√®le Multiplicatif)

O√π:
- T‚Çú = Tendance (Trend)
- S‚Çú = Saisonnalit√© (Seasonal)
- C‚Çú = Cycle (Cyclical)
- I‚Çú = Irr√©gulier/Bruit (Irregular)
```

**Mn√©motechnique: "TSCI"**
```
T - Tendance: Direction long terme (hausse/baisse)
S - Saisonnalit√©: Pattern r√©p√©titif √† p√©riode fixe
C - Cycle: Fluctuations √† long terme (√©conomiques)
I - Irr√©gulier: Variations al√©atoires impr√©visibles
```

---

### 1.3 Visualisation des Composantes

```python
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from statsmodels.tsa.seasonal import seasonal_decompose

# Cr√©er une s√©rie temporelle bancaire
np.random.seed(42)
dates = pd.date_range(start='2020-01-01', periods=48, freq='M')

# Composantes
tendance = np.linspace(100, 180, 48)
saisonnalite = 20 * np.sin(2 * np.pi * np.arange(48) / 12)
bruit = np.random.normal(0, 5, 48)

# D√©p√¥ts mensuels (en millions HTG)
depots = tendance + saisonnalite + bruit

df = pd.DataFrame({'date': dates, 'depots_millions': depots})
df.set_index('date', inplace=True)

# D√©composition
decomposition = seasonal_decompose(df['depots_millions'], model='additive', period=12)

# Visualisation
fig, axes = plt.subplots(4, 1, figsize=(12, 10))
decomposition.observed.plot(ax=axes[0], title='Observ√©')
decomposition.trend.plot(ax=axes[1], title='Tendance')
decomposition.seasonal.plot(ax=axes[2], title='Saisonnalit√©')
decomposition.resid.plot(ax=axes[3], title='R√©sidus')
plt.tight_layout()
plt.show()
```

---

## Partie 2: Stationnarit√©

### 2.1 D√©finition et Importance

**S√©rie stationnaire:** Propri√©t√©s statistiques constantes dans le temps.

```
Conditions de stationnarit√© faible:
1. E[Y‚Çú] = Œº (moyenne constante)
2. Var(Y‚Çú) = œÉ¬≤ (variance constante)
3. Cov(Y‚Çú, Y‚Çú‚Çä‚Çñ) = Œ≥‚Çñ (covariance ne d√©pend que du lag k)
```

**Importance:**
- La plupart des mod√®les (ARIMA) requi√®rent la stationnarit√©
- Une s√©rie non stationnaire donne des r√©gressions fallacieuses
- Il faut transformer avant de mod√©liser

---

### 2.2 Tests de Stationnarit√©

#### Test ADF (Augmented Dickey-Fuller)

```python
from statsmodels.tsa.stattools import adfuller

def test_stationnarite(series, nom="S√©rie"):
    """Test ADF de stationnarit√©"""
    result = adfuller(series.dropna())
    
    print(f"\n=== Test ADF pour {nom} ===")
    print(f"Statistique ADF: {result[0]:.4f}")
    print(f"P-value: {result[1]:.4f}")
    print(f"Lags utilis√©s: {result[2]}")
    print(f"Observations: {result[3]}")
    print("Valeurs critiques:")
    for key, value in result[4].items():
        print(f"  {key}: {value:.4f}")
    
    if result[1] < 0.05:
        print(f"\n‚úì CONCLUSION: {nom} est STATIONNAIRE (p < 0.05)")
        return True
    else:
        print(f"\n‚ö†Ô∏è CONCLUSION: {nom} est NON STATIONNAIRE (p ‚â• 0.05)")
        return False

# Test
test_stationnarite(df['depots_millions'], "D√©p√¥ts")
```

**Interpr√©tation:**
- H‚ÇÄ: La s√©rie a une racine unitaire (non stationnaire)
- H‚ÇÅ: La s√©rie est stationnaire
- Si p-value < 0.05 ‚Üí Rejeter H‚ÇÄ ‚Üí Stationnaire

#### Test KPSS (Kwiatkowski-Phillips-Schmidt-Shin)

```python
from statsmodels.tsa.stattools import kpss

def test_kpss(series, nom="S√©rie"):
    """Test KPSS de stationnarit√©"""
    result = kpss(series.dropna(), regression='c')
    
    print(f"\n=== Test KPSS pour {nom} ===")
    print(f"Statistique KPSS: {result[0]:.4f}")
    print(f"P-value: {result[1]:.4f}")
    print("Valeurs critiques:")
    for key, value in result[3].items():
        print(f"  {key}: {value:.4f}")
    
    if result[1] > 0.05:
        print(f"\n‚úì CONCLUSION: {nom} est STATIONNAIRE (p > 0.05)")
        return True
    else:
        print(f"\n‚ö†Ô∏è CONCLUSION: {nom} est NON STATIONNAIRE (p ‚â§ 0.05)")
        return False

# Note: KPSS a l'hypoth√®se inverse de ADF
# H‚ÇÄ: S√©rie stationnaire
# H‚ÇÅ: S√©rie non stationnaire
```

**Strat√©gie combin√©e:**

| ADF | KPSS | Conclusion |
|-----|------|------------|
| Stationnaire (p<0.05) | Stationnaire (p>0.05) | ‚úì Stationnaire |
| Non stationnaire (p‚â•0.05) | Non stationnaire (p‚â§0.05) | ‚úó Non stationnaire |
| Mixte | Mixte | Diff√©rencier et retester |

---

### 2.3 Transformation pour Stationnarit√©

```python
# 1. Diff√©renciation (retirer la tendance)
df['depots_diff1'] = df['depots_millions'].diff()

# 2. Diff√©renciation saisonni√®re (retirer la saisonnalit√©)
df['depots_diff12'] = df['depots_millions'].diff(12)

# 3. Transformation logarithmique (stabiliser la variance)
df['depots_log'] = np.log(df['depots_millions'])

# 4. Diff√©rence du log (rendements)
df['depots_log_diff'] = np.log(df['depots_millions']).diff()

# V√©rifier la stationnarit√© apr√®s transformation
test_stationnarite(df['depots_diff1'].dropna(), "D√©p√¥ts diff√©renci√©s")
```

---

## Partie 3: Autocorr√©lation

### 3.1 ACF et PACF

```
ACF (Autocorrelation Function):
- Corr√©lation entre Y‚Çú et Y‚Çú‚Çã‚Çñ pour diff√©rents lags k
- Inclut les effets indirects

PACF (Partial Autocorrelation Function):
- Corr√©lation entre Y‚Çú et Y‚Çú‚Çã‚Çñ APR√àS avoir contr√¥l√© pour les lags interm√©diaires
- Effets directs uniquement
```

```python
from statsmodels.graphics.tsaplots import plot_acf, plot_pacf

fig, axes = plt.subplots(1, 2, figsize=(14, 5))

# ACF
plot_acf(df['depots_millions'].dropna(), lags=24, ax=axes[0])
axes[0].set_title('ACF - Autocorr√©lation')

# PACF
plot_pacf(df['depots_millions'].dropna(), lags=24, ax=axes[1])
axes[1].set_title('PACF - Autocorr√©lation Partielle')

plt.tight_layout()
plt.show()
```

---

### 3.2 Interpr√©tation ACF/PACF pour ARIMA

| Pattern ACF | Pattern PACF | Mod√®le sugg√©r√© |
|-------------|--------------|----------------|
| D√©croissance exponentielle | Coupure nette au lag p | AR(p) |
| Coupure nette au lag q | D√©croissance exponentielle | MA(q) |
| D√©croissance des deux | D√©croissance des deux | ARMA(p,q) |

---

## Partie 4: Mod√®les de Pr√©vision

### 4.1 Moyennes Mobiles

```python
# Moyenne mobile simple
df['MM_3'] = df['depots_millions'].rolling(window=3).mean()
df['MM_12'] = df['depots_millions'].rolling(window=12).mean()

# Moyenne mobile exponentielle
df['EMA_3'] = df['depots_millions'].ewm(span=3, adjust=False).mean()

# Visualisation
plt.figure(figsize=(12, 6))
plt.plot(df.index, df['depots_millions'], label='Observ√©', alpha=0.7)
plt.plot(df.index, df['MM_12'], label='MM(12)', linewidth=2)
plt.plot(df.index, df['EMA_3'], label='EMA(3)', linewidth=2)
plt.legend()
plt.title('D√©p√¥ts et Moyennes Mobiles')
plt.show()
```

---

### 4.2 Lissage Exponentiel Simple

```python
from statsmodels.tsa.holtwinters import SimpleExpSmoothing

# Mod√®le
model_ses = SimpleExpSmoothing(df['depots_millions']).fit(smoothing_level=0.3)

# Pr√©vision
forecast_ses = model_ses.forecast(12)
print("Pr√©visions SES (12 mois):", forecast_ses.values)

# Param√®tre alpha:
# - alpha proche de 0: Lissage fort (poids aux anciennes observations)
# - alpha proche de 1: Peu de lissage (poids aux observations r√©centes)
```

---

### 4.3 Holt-Winters (Triple Lissage Exponentiel)

**Composantes:**
- Œ± (alpha): Niveau
- Œ≤ (beta): Tendance
- Œ≥ (gamma): Saisonnalit√©

```python
from statsmodels.tsa.holtwinters import ExponentialSmoothing

# Mod√®le Holt-Winters avec saisonnalit√© additive
model_hw = ExponentialSmoothing(
    df['depots_millions'],
    trend='add',           # Tendance additive
    seasonal='add',        # Saisonnalit√© additive
    seasonal_periods=12    # P√©riode de 12 mois
).fit()

# Pr√©vision 12 mois
forecast_hw = model_hw.forecast(12)

# Visualisation
fig, ax = plt.subplots(figsize=(12, 6))
df['depots_millions'].plot(ax=ax, label='Historique')
forecast_hw.plot(ax=ax, label='Pr√©vision Holt-Winters', style='--')
plt.legend()
plt.title('Pr√©vision des D√©p√¥ts - Holt-Winters')
plt.show()

print(f"\nPr√©visions pour les 12 prochains mois:")
print(forecast_hw)
```

---

### 4.4 ARIMA (AutoRegressive Integrated Moving Average)

**Notation:** ARIMA(p, d, q)
- p = Ordre autor√©gressif (AR)
- d = Ordre de diff√©renciation (I)
- q = Ordre de moyenne mobile (MA)

```python
from statsmodels.tsa.arima.model import ARIMA

# D√©terminer les ordres avec ACF/PACF ou auto_arima
# Exemple: ARIMA(1, 1, 1)
model_arima = ARIMA(df['depots_millions'], order=(1, 1, 1))
results_arima = model_arima.fit()

print(results_arima.summary())

# Pr√©vision
forecast_arima = results_arima.forecast(steps=12)
print("\nPr√©visions ARIMA:")
print(forecast_arima)

# Intervalles de confiance
forecast_ci = results_arima.get_forecast(steps=12)
conf_int = forecast_ci.conf_int()
print("\nIntervalles de confiance √† 95%:")
print(conf_int)
```

---

### 4.5 SARIMA (Seasonal ARIMA)

**Notation:** SARIMA(p, d, q)(P, D, Q, s)
- (p, d, q): Partie non saisonni√®re
- (P, D, Q, s): Partie saisonni√®re, s = p√©riode

```python
from statsmodels.tsa.statespace.sarimax import SARIMAX

# SARIMA avec saisonnalit√© mensuelle (s=12)
model_sarima = SARIMAX(
    df['depots_millions'],
    order=(1, 1, 1),
    seasonal_order=(1, 1, 1, 12)
)
results_sarima = model_sarima.fit(disp=False)

print(results_sarima.summary())

# Pr√©vision avec intervalles
forecast_sarima = results_sarima.get_forecast(steps=12)
forecast_mean = forecast_sarima.predicted_mean
forecast_ci = forecast_sarima.conf_int()

# Visualisation
fig, ax = plt.subplots(figsize=(12, 6))
df['depots_millions'].plot(ax=ax, label='Historique')
forecast_mean.plot(ax=ax, label='Pr√©vision SARIMA', style='--')
ax.fill_between(forecast_ci.index, 
                forecast_ci.iloc[:, 0], 
                forecast_ci.iloc[:, 1], 
                alpha=0.2)
plt.legend()
plt.title('Pr√©vision des D√©p√¥ts - SARIMA')
plt.show()
```

---

### 4.6 S√©lection Automatique avec Auto-ARIMA

```python
# Installation: pip install pmdarima
from pmdarima import auto_arima

# Recherche automatique des meilleurs param√®tres
model_auto = auto_arima(
    df['depots_millions'],
    seasonal=True,
    m=12,  # P√©riode saisonni√®re
    stepwise=True,
    suppress_warnings=True,
    trace=True  # Afficher la progression
)

print(model_auto.summary())

# Pr√©vision
forecast_auto = model_auto.predict(n_periods=12)
print("\nPr√©visions Auto-ARIMA:")
print(forecast_auto)
```

---

### 4.7 Prophet (Facebook)

```python
# Installation: pip install prophet
from prophet import Prophet

# Pr√©parer les donn√©es au format Prophet
df_prophet = df.reset_index()
df_prophet.columns = ['ds', 'y']

# Mod√®le Prophet
model_prophet = Prophet(
    yearly_seasonality=True,
    weekly_seasonality=False,
    daily_seasonality=False
)
model_prophet.fit(df_prophet)

# Cr√©er les dates futures
future = model_prophet.make_future_dataframe(periods=12, freq='M')

# Pr√©vision
forecast_prophet = model_prophet.predict(future)

# Visualisation
fig = model_prophet.plot(forecast_prophet)
plt.title('Pr√©vision Prophet')
plt.show()

# Composantes
fig2 = model_prophet.plot_components(forecast_prophet)
plt.show()
```

---

## Partie 5: √âvaluation des Mod√®les

### 5.1 M√©triques d'√âvaluation

```python
from sklearn.metrics import mean_absolute_error, mean_squared_error

def evaluer_prevision(y_true, y_pred):
    """M√©triques d'√©valuation pour s√©ries temporelles"""
    
    mae = mean_absolute_error(y_true, y_pred)
    mse = mean_squared_error(y_true, y_pred)
    rmse = np.sqrt(mse)
    mape = np.mean(np.abs((y_true - y_pred) / y_true)) * 100
    
    print("=== M√âTRIQUES D'√âVALUATION ===")
    print(f"MAE (Mean Absolute Error): {mae:.2f}")
    print(f"MSE (Mean Squared Error): {mse:.2f}")
    print(f"RMSE (Root MSE): {rmse:.2f}")
    print(f"MAPE (Mean Absolute % Error): {mape:.2f}%")
    
    return {'MAE': mae, 'MSE': mse, 'RMSE': rmse, 'MAPE': mape}
```

**Tableau des m√©triques:**

| M√©trique | Formule | Interpr√©tation |
|----------|---------|----------------|
| **MAE** | Œ£\|Y·µ¢ - ≈∂·µ¢\| / n | Erreur moyenne absolue |
| **MSE** | Œ£(Y·µ¢ - ≈∂·µ¢)¬≤ / n | P√©nalise les grandes erreurs |
| **RMSE** | ‚àöMSE | M√™me unit√© que Y |
| **MAPE** | Œ£\|(Y·µ¢ - ≈∂·µ¢)/Y·µ¢\| √ó 100 / n | Erreur en pourcentage |

---

### 5.2 Validation Crois√©e pour S√©ries Temporelles

```python
from sklearn.model_selection import TimeSeriesSplit

# Important: Ne pas m√©langer les donn√©es!
# Utiliser TimeSeriesSplit

tscv = TimeSeriesSplit(n_splits=5)

errors = []
for train_idx, test_idx in tscv.split(df['depots_millions']):
    train = df['depots_millions'].iloc[train_idx]
    test = df['depots_millions'].iloc[test_idx]
    
    # Entra√Æner le mod√®le
    model = ExponentialSmoothing(
        train, 
        trend='add', 
        seasonal='add', 
        seasonal_periods=12
    ).fit()
    
    # Pr√©dire
    pred = model.forecast(len(test))
    
    # Calculer l'erreur
    mape = np.mean(np.abs((test.values - pred.values) / test.values)) * 100
    errors.append(mape)
    print(f"Fold MAPE: {mape:.2f}%")

print(f"\nMAPE moyen: {np.mean(errors):.2f}%")
```

---

### 5.3 Crit√®res de S√©lection de Mod√®le

```
AIC (Akaike Information Criterion):
AIC = 2k - 2ln(L)

BIC (Bayesian Information Criterion):
BIC = k√óln(n) - 2ln(L)

O√π:
- k = nombre de param√®tres
- n = nombre d'observations
- L = vraisemblance

R√®gle: Plus bas = Meilleur
```

```python
# Comparer plusieurs mod√®les
models_comparison = []

# Mod√®le 1: ARIMA(1,1,1)
m1 = ARIMA(df['depots_millions'], order=(1,1,1)).fit()
models_comparison.append({
    'Mod√®le': 'ARIMA(1,1,1)',
    'AIC': m1.aic,
    'BIC': m1.bic
})

# Mod√®le 2: ARIMA(2,1,1)
m2 = ARIMA(df['depots_millions'], order=(2,1,1)).fit()
models_comparison.append({
    'Mod√®le': 'ARIMA(2,1,1)',
    'AIC': m2.aic,
    'BIC': m2.bic
})

# Mod√®le 3: ARIMA(1,1,2)
m3 = ARIMA(df['depots_millions'], order=(1,1,2)).fit()
models_comparison.append({
    'Mod√®le': 'ARIMA(1,1,2)',
    'AIC': m3.aic,
    'BIC': m3.bic
})

comparison_df = pd.DataFrame(models_comparison).sort_values('AIC')
print(comparison_df)
```

---

## Partie 6: Applications Bancaires

### 6.1 Cas 1: Pr√©vision de Liquidit√©

```python
"""
Objectif: Pr√©voir les retraits nets pour g√©rer la liquidit√©
"""
import pandas as pd
import numpy as np
from statsmodels.tsa.holtwinters import ExponentialSmoothing

# Donn√©es de retraits nets (en millions HTG)
np.random.seed(42)
dates = pd.date_range(start='2022-01-01', periods=36, freq='M')

# Pattern: Pics en fin de mois, augmentation en d√©cembre
retraits = 50 + \
           10 * np.sin(2 * np.pi * np.arange(36) / 12) + \
           np.linspace(0, 20, 36) + \
           np.random.normal(0, 5, 36)

df_liquidite = pd.DataFrame({
    'date': dates,
    'retraits_nets': retraits
}).set_index('date')

# Mod√®le Holt-Winters
model_liq = ExponentialSmoothing(
    df_liquidite['retraits_nets'],
    trend='add',
    seasonal='add',
    seasonal_periods=12
).fit()

# Pr√©vision 6 mois
prevision_liq = model_liq.forecast(6)

print("=== PR√âVISION DE LIQUIDIT√â ===")
print("\nRetraits pr√©vus pour les 6 prochains mois:")
for date, val in prevision_liq.items():
    print(f"  {date.strftime('%Y-%m')}: {val:.1f} millions HTG")

# Recommandation
max_retrait = prevision_liq.max()
print(f"\n‚ö†Ô∏è Pic pr√©vu: {max_retrait:.1f} millions HTG")
print(f"Recommandation: Maintenir une r√©serve de {max_retrait * 1.2:.1f} millions HTG")
```

---

### 6.2 Cas 2: Pr√©vision des D√©fauts de Paiement

```python
"""
Objectif: Pr√©voir le taux de d√©faut trimestriel
"""
from statsmodels.tsa.arima.model import ARIMA

# Donn√©es de taux de d√©faut (%)
np.random.seed(42)
dates = pd.date_range(start='2018-01-01', periods=24, freq='Q')

# Taux de d√©faut avec cycle √©conomique
taux_defaut = 3.5 + \
              1.5 * np.sin(2 * np.pi * np.arange(24) / 8) + \
              np.random.normal(0, 0.3, 24)

df_defaut = pd.DataFrame({
    'date': dates,
    'taux_defaut': taux_defaut
}).set_index('date')

# Mod√®le ARIMA
model_defaut = ARIMA(df_defaut['taux_defaut'], order=(2, 0, 1)).fit()

# Pr√©vision 4 trimestres
prevision_defaut = model_defaut.get_forecast(4)
mean_forecast = prevision_defaut.predicted_mean
conf_int = prevision_defaut.conf_int()

print("=== PR√âVISION DU TAUX DE D√âFAUT ===")
print("\nTaux pr√©vu (avec IC 95%):")
for i, (idx, val) in enumerate(mean_forecast.items()):
    lower = conf_int.iloc[i, 0]
    upper = conf_int.iloc[i, 1]
    print(f"  {idx.strftime('%Y-Q%q')}: {val:.2f}% [{lower:.2f}% - {upper:.2f}%]")

# Alerte si taux > seuil
seuil_alerte = 5.0
if mean_forecast.max() > seuil_alerte:
    print(f"\nüö® ALERTE: Taux de d√©faut pr√©vu > {seuil_alerte}%")
    print("   Actions recommand√©es:")
    print("   - Renforcer les crit√®res d'octroi")
    print("   - Augmenter les provisions")
```

---

### 6.3 Cas 3: Pr√©vision du Volume de Transactions

```python
"""
Objectif: Pr√©voir le volume de transactions pour dimensionner l'infrastructure
"""
from prophet import Prophet

# Donn√©es de transactions journali√®res
np.random.seed(42)
dates = pd.date_range(start='2023-01-01', periods=365, freq='D')

# Pattern: Weekend faible, pic en fin de mois
base = 10000
weekly_pattern = np.array([1.2, 1.1, 1.0, 1.0, 1.3, 0.6, 0.5])  # Lun-Dim
day_of_week = np.array([d.weekday() for d in dates])
weekly_effect = np.array([weekly_pattern[d] for d in day_of_week])

# Effet fin de mois
day_of_month = np.array([d.day for d in dates])
end_month_effect = np.where(day_of_month > 25, 1.4, 1.0)

transactions = base * weekly_effect * end_month_effect + np.random.normal(0, 500, 365)

df_trans = pd.DataFrame({
    'ds': dates,
    'y': transactions
})

# Mod√®le Prophet
model_trans = Prophet(
    yearly_seasonality=True,
    weekly_seasonality=True,
    daily_seasonality=False
)
model_trans.add_seasonality(name='monthly', period=30.5, fourier_order=5)
model_trans.fit(df_trans)

# Pr√©vision 30 jours
future = model_trans.make_future_dataframe(periods=30)
forecast_trans = model_trans.predict(future)

# Identifier les pics
peaks = forecast_trans.tail(30).nlargest(5, 'yhat')
print("=== PR√âVISION DU VOLUME DE TRANSACTIONS ===")
print("\n5 jours de pic pr√©vus:")
for _, row in peaks.iterrows():
    print(f"  {row['ds'].strftime('%Y-%m-%d')}: {row['yhat']:.0f} transactions")

print(f"\nCapacit√© recommand√©e: {forecast_trans.tail(30)['yhat'].max() * 1.3:.0f} trans/jour")
```

---

## Partie 7: Formules Essentielles

### 7.1 Tableau R√©capitulatif

| Mod√®le | Formule/Structure | Usage |
|--------|-------------------|-------|
| **SES** | ≈∂‚Çú‚Çä‚ÇÅ = Œ±Y‚Çú + (1-Œ±)≈∂‚Çú | S√©rie sans tendance ni saison |
| **Holt** | Niveau + Tendance | S√©rie avec tendance |
| **Holt-Winters** | Niveau + Tendance + Saison | S√©rie compl√®te |
| **AR(p)** | Y‚Çú = œÜ‚ÇÅY‚Çú‚Çã‚ÇÅ + ... + œÜ‚ÇöY‚Çú‚Çã‚Çö + Œµ‚Çú | Autocorr√©lation |
| **MA(q)** | Y‚Çú = Œµ‚Çú + Œ∏‚ÇÅŒµ‚Çú‚Çã‚ÇÅ + ... + Œ∏qŒµ‚Çú‚Çãq | Moyenne mobile |
| **ARIMA(p,d,q)** | AR + I + MA | S√©rie non stationnaire |
| **SARIMA** | ARIMA + composante saisonni√®re | S√©rie avec saison |

---

### 7.2 Mn√©motechniques

**"SADIM" pour les √©tapes:**
```
S - Stationnarit√©: Tester (ADF, KPSS)
A - ACF/PACF: Analyser les corr√©lations
D - D√©terminer: Choisir p, d, q
I - Impl√©menter: Ajuster le mod√®le
M - Mesurer: √âvaluer (AIC, RMSE, MAPE)
```

**"ARIMA" pour retenir les composantes:**
```
A - AutoRegressive: Pass√© de Y
R - ... (R de ARIMA)
I - Integrated: Diff√©renciation
M - Moving Average: Pass√© des erreurs
A - ... (A de ARIMA)
```

---

## Partie 8: Checklist Analyse de S√©ries Temporelles

```
‚ñ° 1. Visualiser la s√©rie (tendance, saisonnalit√©?)
‚ñ° 2. D√©composer (additive ou multiplicative?)
‚ñ° 3. Tester la stationnarit√© (ADF, KPSS)
‚ñ° 4. Transformer si n√©cessaire (diff, log)
‚ñ° 5. Analyser ACF/PACF
‚ñ° 6. Choisir le mod√®le (Holt-Winters, ARIMA, Prophet)
‚ñ° 7. Ajuster et diagnostiquer les r√©sidus
‚ñ° 8. Valider (AIC, BIC, cross-validation temporelle)
‚ñ° 9. Pr√©voir avec intervalles de confiance
‚ñ° 10. Interpr√©ter pour le business
```

---

## R√©sum√© Express: Questions Probables

1. **"Comment tester si une s√©rie est stationnaire?"**
   ‚Üí Test ADF: p < 0.05 = stationnaire

2. **"Quelle est la diff√©rence entre ARIMA et SARIMA?"**
   ‚Üí SARIMA inclut une composante saisonni√®re (P, D, Q, s)

3. **"Comment choisir entre plusieurs mod√®les?"**
   ‚Üí AIC/BIC plus bas = meilleur mod√®le

4. **"Quelles sont les composantes d'une s√©rie temporelle?"**
   ‚Üí TSCI: Tendance, Saisonnalit√©, Cycle, Irr√©gulier

5. **"Comment pr√©voir les d√©p√¥ts du mois prochain?"**
   ‚Üí Holt-Winters ou SARIMA avec saisonnalit√© mensuelle

6. **"Qu'est-ce que le MAPE?"**
   ‚Üí Mean Absolute Percentage Error - erreur moyenne en %

---

*Document pr√©par√© pour l'examen Data Analyst - UniBank Haiti*
*S√©ries Temporelles: Ma√Ætriser la dimension temps*
