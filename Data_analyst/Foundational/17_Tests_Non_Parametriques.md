# Manuel de Pr√©paration: Tests Non-Param√©triques

## Introduction

Les tests non-param√©triques (ou tests distribution-free) sont des alternatives aux tests param√©triques classiques lorsque les hypoth√®ses de normalit√© ne sont pas respect√©es. Dans le contexte bancaire, o√π les distributions sont souvent asym√©triques (revenus, montants de transactions), ces tests sont particuli√®rement utiles.

---

## Partie 1: Quand Utiliser les Tests Non-Param√©triques?

### 1.1 Conditions d'Utilisation

**Utiliser les tests non-param√©triques quand:**
- La distribution n'est pas normale
- L'√©chantillon est petit (n < 30)
- Les donn√©es sont ordinales (pas quantitatives)
- Il y a des outliers importants
- Les variances sont tr√®s in√©gales

**Avantages:**
- Moins d'hypoth√®ses requises
- Robustes aux outliers
- Applicables aux donn√©es ordinales

**Inconv√©nients:**
- Moins de puissance statistique (si normalit√© respect√©e)
- Moins informatifs (bas√©s sur les rangs)

---

### 1.2 Correspondance Tests Param√©triques vs Non-Param√©triques

| Situation | Test Param√©trique | Test Non-Param√©trique |
|-----------|------------------|----------------------|
| 2 groupes ind√©pendants | t-test ind√©pendant | **Mann-Whitney U** |
| 2 groupes appari√©s | t-test appari√© | **Wilcoxon sign√©** |
| 3+ groupes ind√©pendants | ANOVA | **Kruskal-Wallis** |
| 3+ groupes appari√©s | ANOVA mesures r√©p√©t√©es | **Friedman** |
| Corr√©lation | Pearson | **Spearman** / **Kendall** |
| Association cat√©gorielle | - | **Chi-carr√©** |

---

### 1.3 Mn√©motechnique: "MWKF-SK"

```
M - Mann-Whitney: 2 groupes ind√©pendants
W - Wilcoxon: 2 groupes appari√©s
K - Kruskal-Wallis: 3+ groupes ind√©pendants
F - Friedman: 3+ groupes appari√©s
S - Spearman: Corr√©lation de rang
K - Kendall: Corr√©lation de rang (alternative)
```

---

## Partie 2: Test de Mann-Whitney U

### 2.1 Description

**Alternative au:** t-test pour √©chantillons ind√©pendants

**Hypoth√®ses:**
- H‚ÇÄ: Les deux groupes ont la m√™me distribution
- H‚ÇÅ: Les distributions sont diff√©rentes

**Principe:** Compare les rangs des observations entre les deux groupes.

---

### 2.2 Impl√©mentation Python

```python
import numpy as np
import pandas as pd
from scipy import stats
import matplotlib.pyplot as plt

# Exemple bancaire: Montants de transactions par type de client
np.random.seed(42)

# Clients retail (distribution asym√©trique)
montants_retail = np.random.exponential(scale=5000, size=50)

# Clients premium (montants plus √©lev√©s, aussi asym√©triques)
montants_premium = np.random.exponential(scale=15000, size=45)

# Visualiser les distributions
fig, axes = plt.subplots(1, 2, figsize=(12, 4))
axes[0].hist(montants_retail, bins=20, alpha=0.7, label='Retail')
axes[0].hist(montants_premium, bins=20, alpha=0.7, label='Premium')
axes[0].legend()
axes[0].set_title('Distribution des Montants')

# Test de normalit√©
_, p_retail = stats.shapiro(montants_retail)
_, p_premium = stats.shapiro(montants_premium)
print(f"Shapiro-Wilk Retail: p = {p_retail:.4f}")
print(f"Shapiro-Wilk Premium: p = {p_premium:.4f}")
# Si p < 0.05, distribution non normale ‚Üí utiliser Mann-Whitney

# Test de Mann-Whitney U
statistic, p_value = stats.mannwhitneyu(
    montants_retail, 
    montants_premium, 
    alternative='two-sided'
)

print(f"\n=== Test de Mann-Whitney U ===")
print(f"Statistique U: {statistic:.2f}")
print(f"P-value: {p_value:.4f}")

if p_value < 0.05:
    print("‚Üí Diff√©rence significative entre les groupes")
else:
    print("‚Üí Pas de diff√©rence significative")

# Taille d'effet (r = Z / ‚àöN)
n1, n2 = len(montants_retail), len(montants_premium)
z_score = stats.norm.ppf(1 - p_value/2)
effect_size = z_score / np.sqrt(n1 + n2)
print(f"Taille d'effet (r): {effect_size:.3f}")
```

---

### 2.3 Interpr√©tation de la Statistique U

```
U mesure le nombre de fois o√π une observation d'un groupe 
d√©passe une observation de l'autre groupe.

U minimum = 0 (aucun chevauchement)
U maximum = n‚ÇÅ √ó n‚ÇÇ (chevauchement total)

Taille d'effet (r):
- r < 0.3: Petit effet
- r = 0.3-0.5: Effet moyen
- r > 0.5: Grand effet
```

---

### 2.4 Application Bancaire

```python
"""
Cas: Comparer les d√©lais de remboursement entre deux agences
"""

# Donn√©es: Jours de retard de paiement
agence_a = [5, 12, 3, 45, 7, 2, 8, 15, 90, 4, 6, 10, 25, 3, 8]
agence_b = [2, 4, 1, 5, 3, 2, 6, 4, 3, 2, 5, 4, 7, 3, 2, 4, 5]

# Test
stat, p = stats.mannwhitneyu(agence_a, agence_b, alternative='greater')

print("=== Comparaison des D√©lais de Retard ===")
print(f"M√©diane Agence A: {np.median(agence_a):.1f} jours")
print(f"M√©diane Agence B: {np.median(agence_b):.1f} jours")
print(f"P-value (A > B): {p:.4f}")

if p < 0.05:
    print("\n‚ö†Ô∏è L'Agence A a des retards significativement plus longs")
    print("   Recommandation: Audit des processus de recouvrement")
```

---

## Partie 3: Test de Wilcoxon Sign√©

### 3.1 Description

**Alternative au:** t-test pour √©chantillons appari√©s

**Usage:** Comparer deux mesures sur les m√™mes sujets (avant/apr√®s, deux conditions)

**Hypoth√®ses:**
- H‚ÇÄ: La distribution des diff√©rences est sym√©trique autour de 0
- H‚ÇÅ: Les diff√©rences ne sont pas centr√©es sur 0

---

### 3.2 Impl√©mentation Python

```python
from scipy.stats import wilcoxon

# Exemple: Satisfaction client avant et apr√®s une campagne
np.random.seed(42)

n_clients = 30
satisfaction_avant = np.random.randint(1, 8, n_clients)  # Score 1-10
# Am√©lioration apr√®s campagne (pas toujours)
satisfaction_apres = satisfaction_avant + np.random.choice([-1, 0, 1, 2], n_clients, p=[0.1, 0.2, 0.4, 0.3])
satisfaction_apres = np.clip(satisfaction_apres, 1, 10)

# Calculer les diff√©rences
differences = satisfaction_apres - satisfaction_avant

print("=== Analyse Avant/Apr√®s Campagne ===")
print(f"Satisfaction moyenne avant: {satisfaction_avant.mean():.2f}")
print(f"Satisfaction moyenne apr√®s: {satisfaction_apres.mean():.2f}")
print(f"Diff√©rence m√©diane: {np.median(differences):.2f}")

# Test de Wilcoxon
statistic, p_value = wilcoxon(satisfaction_avant, satisfaction_apres, alternative='less')

print(f"\nTest de Wilcoxon:")
print(f"Statistique W: {statistic:.2f}")
print(f"P-value: {p_value:.4f}")

if p_value < 0.05:
    print("\n‚úì Am√©lioration significative de la satisfaction")
else:
    print("\n‚úó Pas d'am√©lioration significative")
```

---

### 3.3 Application Bancaire

```python
"""
Cas: √âvaluer l'effet d'une formation sur la productivit√© des conseillers
"""

# Productivit√© (nombre de dossiers trait√©s par jour)
productivite_avant = [12, 15, 8, 10, 14, 9, 11, 13, 7, 16]
productivite_apres = [14, 17, 10, 12, 15, 11, 14, 16, 9, 18]

# Test
stat, p = wilcoxon(productivite_avant, productivite_apres, alternative='less')

print("=== √âvaluation de la Formation ===")
print(f"Productivit√© m√©diane avant: {np.median(productivite_avant):.1f}")
print(f"Productivit√© m√©diane apr√®s: {np.median(productivite_apres):.1f}")
print(f"P-value: {p:.4f}")

if p < 0.05:
    amelioration = np.median(productivite_apres) - np.median(productivite_avant)
    print(f"\n‚úì Formation efficace (+{amelioration:.1f} dossiers/jour)")
    print("   ROI: Calculer co√ªt formation vs gain productivit√©")
```

---

## Partie 4: Test de Kruskal-Wallis

### 4.1 Description

**Alternative √†:** ANOVA √† un facteur

**Usage:** Comparer 3 groupes ou plus

**Hypoth√®ses:**
- H‚ÇÄ: Toutes les populations ont la m√™me distribution
- H‚ÇÅ: Au moins une population diff√®re

---

### 4.2 Impl√©mentation Python

```python
from scipy.stats import kruskal

# Exemple: Temps de traitement de dossiers par agence
np.random.seed(42)

agence_centre = np.random.exponential(5, 25)  # Jours
agence_nord = np.random.exponential(7, 30)
agence_sud = np.random.exponential(4, 28)

# Test de Kruskal-Wallis
stat, p = kruskal(agence_centre, agence_nord, agence_sud)

print("=== Comparaison des Temps de Traitement ===")
print(f"M√©diane Centre: {np.median(agence_centre):.2f} jours")
print(f"M√©diane Nord: {np.median(agence_nord):.2f} jours")
print(f"M√©diane Sud: {np.median(agence_sud):.2f} jours")
print(f"\nKruskal-Wallis H: {stat:.2f}")
print(f"P-value: {p:.4f}")

if p < 0.05:
    print("\n‚ö†Ô∏è Diff√©rences significatives entre agences")
    print("   ‚Üí Effectuer des tests post-hoc")
```

---

### 4.3 Tests Post-Hoc (Comparaisons Multiples)

```python
from scipy.stats import mannwhitneyu
from itertools import combinations

def posthoc_mannwhitney(groups, group_names, alpha=0.05):
    """Tests post-hoc Mann-Whitney avec correction de Bonferroni"""
    
    n_comparisons = len(list(combinations(range(len(groups)), 2)))
    alpha_corrected = alpha / n_comparisons
    
    print(f"\n=== Tests Post-Hoc (Bonferroni Œ± = {alpha_corrected:.4f}) ===")
    
    results = []
    for (i, j) in combinations(range(len(groups)), 2):
        stat, p = mannwhitneyu(groups[i], groups[j], alternative='two-sided')
        significant = "***" if p < alpha_corrected else "n.s."
        print(f"{group_names[i]} vs {group_names[j]}: U={stat:.1f}, p={p:.4f} {significant}")
        results.append({
            'Comparaison': f"{group_names[i]} vs {group_names[j]}",
            'U': stat,
            'p-value': p,
            'Significatif': p < alpha_corrected
        })
    
    return pd.DataFrame(results)

# Application
groups = [agence_centre, agence_nord, agence_sud]
names = ['Centre', 'Nord', 'Sud']
posthoc_mannwhitney(groups, names)
```

---

### 4.4 Application Bancaire

```python
"""
Cas: Comparer les scores de satisfaction par segment client
"""

# Scores de satisfaction (1-10)
retail = [6, 5, 7, 4, 6, 5, 8, 6, 5, 7, 4, 6, 5, 7, 6]
premium = [7, 8, 9, 7, 8, 9, 8, 7, 9, 8, 7, 8]
private = [9, 10, 8, 9, 10, 9, 9, 10, 8, 9]

# Test
stat, p = kruskal(retail, premium, private)

print("=== Satisfaction par Segment ===")
print(f"M√©diane Retail: {np.median(retail):.1f}")
print(f"M√©diane Premium: {np.median(premium):.1f}")
print(f"M√©diane Private: {np.median(private):.1f}")
print(f"\nKruskal-Wallis: H={stat:.2f}, p={p:.4f}")

if p < 0.05:
    print("\n‚úì Diff√©rences significatives de satisfaction")
    print("   Priorit√©: Am√©liorer l'exp√©rience Retail")
```

---

## Partie 5: Test de Friedman

### 5.1 Description

**Alternative √†:** ANOVA √† mesures r√©p√©t√©es

**Usage:** Comparer 3+ conditions sur les m√™mes sujets

---

### 5.2 Impl√©mentation Python

```python
from scipy.stats import friedmanchisquare

# Exemple: √âvaluation de 3 processus par les m√™mes √©valuateurs
np.random.seed(42)

n_evaluateurs = 12
processus_a = np.random.randint(5, 10, n_evaluateurs)
processus_b = np.random.randint(6, 10, n_evaluateurs)
processus_c = np.random.randint(4, 9, n_evaluateurs)

# Test de Friedman
stat, p = friedmanchisquare(processus_a, processus_b, processus_c)

print("=== Comparaison des Processus ===")
print(f"Score m√©dian Processus A: {np.median(processus_a):.1f}")
print(f"Score m√©dian Processus B: {np.median(processus_b):.1f}")
print(f"Score m√©dian Processus C: {np.median(processus_c):.1f}")
print(f"\nFriedman œá¬≤: {stat:.2f}")
print(f"P-value: {p:.4f}")

if p < 0.05:
    print("\n‚úì Diff√©rences significatives entre processus")
```

---

## Partie 6: Corr√©lations Non-Param√©triques

### 6.1 Corr√©lation de Spearman

**Usage:** Corr√©lation bas√©e sur les rangs (relation monotone, pas n√©cessairement lin√©aire)

```python
from scipy.stats import spearmanr

# Exemple: Relation anciennet√© et fid√©lit√© client
anciennete = [2, 5, 1, 8, 3, 10, 4, 6, 12, 7]
score_fidelite = [45, 72, 30, 88, 55, 95, 60, 78, 92, 80]

# Corr√©lation de Spearman
rho, p = spearmanr(anciennete, score_fidelite)

print("=== Corr√©lation Anciennet√©-Fid√©lit√© ===")
print(f"Spearman œÅ: {rho:.3f}")
print(f"P-value: {p:.4f}")

# Interpr√©tation
if abs(rho) < 0.3:
    force = "faible"
elif abs(rho) < 0.7:
    force = "mod√©r√©e"
else:
    force = "forte"

direction = "positive" if rho > 0 else "n√©gative"
print(f"\n‚Üí Corr√©lation {force} et {direction}")
```

---

### 6.2 Corr√©lation de Kendall (Tau)

**Usage:** Alternative √† Spearman, plus robuste pour petits √©chantillons

```python
from scipy.stats import kendalltau

tau, p = kendalltau(anciennete, score_fidelite)

print("=== Corr√©lation de Kendall ===")
print(f"Kendall œÑ: {tau:.3f}")
print(f"P-value: {p:.4f}")
```

---

### 6.3 Comparaison Pearson vs Spearman vs Kendall

| Crit√®re | Pearson | Spearman | Kendall |
|---------|---------|----------|---------|
| Type de relation | Lin√©aire | Monotone | Monotone |
| Type de donn√©es | Continues | Ordinales/Continues | Ordinales/Continues |
| Sensibilit√© outliers | √âlev√©e | Faible | Faible |
| Petits √©chantillons | Moins fiable | OK | Meilleur |
| Interpr√©tation | Variance partag√©e | Concordance des rangs | Paires concordantes |

---

### 6.4 Application Bancaire: Choix de la Corr√©lation

```python
"""
Cas: Analyser la relation entre revenus et montant de d√©p√¥ts
"""
import matplotlib.pyplot as plt

# Donn√©es (revenus tr√®s asym√©triques)
np.random.seed(42)
revenus = np.random.exponential(50000, 100)  # Distribution asym√©trique
depots = 0.3 * revenus + np.random.exponential(10000, 100)

# Visualiser
fig, ax = plt.subplots(figsize=(8, 6))
ax.scatter(revenus, depots, alpha=0.6)
ax.set_xlabel('Revenus (HTG)')
ax.set_ylabel('D√©p√¥ts (HTG)')
ax.set_title('Relation Revenus-D√©p√¥ts')

# Calculer les trois corr√©lations
from scipy.stats import pearsonr, spearmanr, kendalltau

r_pearson, p_pearson = pearsonr(revenus, depots)
r_spearman, p_spearman = spearmanr(revenus, depots)
r_kendall, p_kendall = kendalltau(revenus, depots)

print("=== Comparaison des Corr√©lations ===")
print(f"Pearson r:  {r_pearson:.3f} (p={p_pearson:.4f})")
print(f"Spearman œÅ: {r_spearman:.3f} (p={p_spearman:.4f})")
print(f"Kendall œÑ:  {r_kendall:.3f} (p={p_kendall:.4f})")

# Recommandation
print("\nüìä Recommandation:")
print("   Distribution asym√©trique ‚Üí Utiliser Spearman")
print(f"   Interpr√©tation: Corr√©lation mod√©r√©e positive ({r_spearman:.2f})")
```

---

## Partie 7: Test du Chi-Carr√©

### 7.1 Chi-Carr√© d'Ind√©pendance

**Usage:** Tester l'association entre deux variables cat√©gorielles

```python
from scipy.stats import chi2_contingency

# Exemple: Type de client vs type de produit pr√©f√©r√©
# Tableau de contingence
data = np.array([
    [120, 80, 50],   # Retail: √âpargne, Cr√©dit, Assurance
    [60, 100, 40],   # Premium
    [20, 30, 50]     # Private
])

chi2, p, dof, expected = chi2_contingency(data)

print("=== Test du Chi-Carr√© d'Ind√©pendance ===")
print(f"Chi¬≤ = {chi2:.2f}")
print(f"Degr√©s de libert√© = {dof}")
print(f"P-value = {p:.4f}")

if p < 0.05:
    print("\n‚úì Association significative entre segment et produit pr√©f√©r√©")
else:
    print("\n‚úó Pas d'association significative")

# Tableau des fr√©quences attendues
print("\nFr√©quences attendues:")
print(pd.DataFrame(expected, 
                   index=['Retail', 'Premium', 'Private'],
                   columns=['√âpargne', 'Cr√©dit', 'Assurance']).round(1))

# V de Cramer (taille d'effet)
n = data.sum()
min_dim = min(data.shape) - 1
v_cramer = np.sqrt(chi2 / (n * min_dim))
print(f"\nV de Cramer: {v_cramer:.3f}")
```

---

### 7.2 Chi-Carr√© de Conformit√© (Goodness of Fit)

```python
from scipy.stats import chisquare

# Exemple: V√©rifier si les d√©fauts sont uniform√©ment r√©partis par trimestre
defauts_observes = [45, 52, 38, 65]  # Par trimestre
defauts_attendus = [50, 50, 50, 50]  # Si uniforme

chi2, p = chisquare(defauts_observes, defauts_attendus)

print("=== Test de Conformit√© ===")
print(f"D√©fauts observ√©s: {defauts_observes}")
print(f"D√©fauts attendus: {defauts_attendus}")
print(f"\nChi¬≤ = {chi2:.2f}, p = {p:.4f}")

if p < 0.05:
    print("\n‚ö†Ô∏è Distribution non uniforme")
    print("   Le Q4 a significativement plus de d√©fauts")
```

---

## Partie 8: Tableau R√©capitulatif des Tests

### 8.1 Guide de S√©lection

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    S√âLECTION DU TEST                            ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  Donn√©es normales?                                              ‚îÇ
‚îÇ  ‚îú‚îÄ‚îÄ OUI ‚Üí Tests param√©triques                                  ‚îÇ
‚îÇ  ‚îÇ   ‚îú‚îÄ‚îÄ 2 groupes ind√©p. ‚Üí t-test                              ‚îÇ
‚îÇ  ‚îÇ   ‚îú‚îÄ‚îÄ 2 groupes appari√©s ‚Üí t-test appari√©                    ‚îÇ
‚îÇ  ‚îÇ   ‚îú‚îÄ‚îÄ 3+ groupes ind√©p. ‚Üí ANOVA                              ‚îÇ
‚îÇ  ‚îÇ   ‚îî‚îÄ‚îÄ Corr√©lation ‚Üí Pearson                                  ‚îÇ
‚îÇ  ‚îÇ                                                              ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ NON ‚Üí Tests non-param√©triques                              ‚îÇ
‚îÇ      ‚îú‚îÄ‚îÄ 2 groupes ind√©p. ‚Üí Mann-Whitney U                      ‚îÇ
‚îÇ      ‚îú‚îÄ‚îÄ 2 groupes appari√©s ‚Üí Wilcoxon sign√©                    ‚îÇ
‚îÇ      ‚îú‚îÄ‚îÄ 3+ groupes ind√©p. ‚Üí Kruskal-Wallis                     ‚îÇ
‚îÇ      ‚îú‚îÄ‚îÄ 3+ groupes appari√©s ‚Üí Friedman                         ‚îÇ
‚îÇ      ‚îú‚îÄ‚îÄ Corr√©lation ‚Üí Spearman / Kendall                       ‚îÇ
‚îÇ      ‚îî‚îÄ‚îÄ Variables cat√©gorielles ‚Üí Chi-carr√©                    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

### 8.2 Formules Cl√©s

| Test | Statistique | Distribution |
|------|-------------|--------------|
| Mann-Whitney | U = n‚ÇÅn‚ÇÇ + n‚ÇÅ(n‚ÇÅ+1)/2 - R‚ÇÅ | Approx. normale si n > 20 |
| Wilcoxon | W = Œ£ rangs positifs | Approx. normale si n > 25 |
| Kruskal-Wallis | H = 12/N(N+1) √ó Œ£(R¬≤·µ¢/n·µ¢) - 3(N+1) | Chi-carr√© (k-1) |
| Spearman | œÅ = 1 - 6Œ£d¬≤·µ¢ / n(n¬≤-1) | t avec n-2 df |
| Chi-carr√© | œá¬≤ = Œ£(O-E)¬≤/E | Chi-carr√© (df) |

---

## Partie 9: Code Express

### 9.1 Fonction de S√©lection Automatique

```python
def choisir_test_comparaison(groupe1, groupe2, apparie=False, alpha=0.05):
    """
    Choisit et ex√©cute le test appropri√© pour comparer deux groupes
    """
    from scipy import stats
    
    print("=== ANALYSE COMPARATIVE ===\n")
    
    # √âtape 1: Tester la normalit√©
    _, p1 = stats.shapiro(groupe1) if len(groupe1) < 5000 else (0, 0)
    _, p2 = stats.shapiro(groupe2) if len(groupe2) < 5000 else (0, 0)
    
    normal1 = p1 > alpha
    normal2 = p2 > alpha
    
    print(f"Normalit√© Groupe 1: {'Oui' if normal1 else 'Non'} (p={p1:.4f})")
    print(f"Normalit√© Groupe 2: {'Oui' if normal2 else 'Non'} (p={p2:.4f})")
    
    # √âtape 2: Choisir le test
    if normal1 and normal2:
        print("\n‚Üí Distributions normales: Test param√©trique")
        if apparie:
            stat, p = stats.ttest_rel(groupe1, groupe2)
            test_nom = "t-test appari√©"
        else:
            stat, p = stats.ttest_ind(groupe1, groupe2)
            test_nom = "t-test ind√©pendant"
    else:
        print("\n‚Üí Distributions non normales: Test non-param√©trique")
        if apparie:
            stat, p = stats.wilcoxon(groupe1, groupe2)
            test_nom = "Wilcoxon sign√©"
        else:
            stat, p = stats.mannwhitneyu(groupe1, groupe2)
            test_nom = "Mann-Whitney U"
    
    # R√©sultats
    print(f"\nTest utilis√©: {test_nom}")
    print(f"Statistique: {stat:.4f}")
    print(f"P-value: {p:.4f}")
    
    if p < alpha:
        print(f"\n‚úì SIGNIFICATIF (p < {alpha})")
    else:
        print(f"\n‚úó NON SIGNIFICATIF (p ‚â• {alpha})")
    
    return {'test': test_nom, 'statistic': stat, 'p_value': p}

# Utilisation
result = choisir_test_comparaison(agence_a, agence_b)
```

---

### 9.2 Rapport Complet Non-Param√©trique

```python
def rapport_nonparametrique(groupes, noms, alpha=0.05):
    """
    G√©n√®re un rapport complet pour l'analyse non-param√©trique
    """
    from scipy import stats
    
    print("=" * 60)
    print("RAPPORT D'ANALYSE NON-PARAM√âTRIQUE")
    print("=" * 60)
    
    # Statistiques descriptives
    print("\n1. STATISTIQUES DESCRIPTIVES")
    print("-" * 40)
    for nom, groupe in zip(noms, groupes):
        print(f"\n{nom}:")
        print(f"  N = {len(groupe)}")
        print(f"  M√©diane = {np.median(groupe):.2f}")
        print(f"  IQR = {np.percentile(groupe, 75) - np.percentile(groupe, 25):.2f}")
        print(f"  Min-Max = [{np.min(groupe):.2f}, {np.max(groupe):.2f}]")
    
    # Tests de normalit√©
    print("\n2. TESTS DE NORMALIT√â (Shapiro-Wilk)")
    print("-" * 40)
    for nom, groupe in zip(noms, groupes):
        if len(groupe) < 5000:
            stat, p = stats.shapiro(groupe)
            result = "Normal" if p > alpha else "Non normal"
            print(f"{nom}: W={stat:.4f}, p={p:.4f} ‚Üí {result}")
    
    # Test global
    print("\n3. TEST GLOBAL (Kruskal-Wallis)")
    print("-" * 40)
    if len(groupes) >= 2:
        stat, p = stats.kruskal(*groupes)
        print(f"H = {stat:.4f}")
        print(f"P-value = {p:.4f}")
        if p < alpha:
            print("‚Üí Diff√©rences significatives d√©tect√©es")
            
            # Tests post-hoc
            print("\n4. TESTS POST-HOC (Mann-Whitney avec Bonferroni)")
            print("-" * 40)
            from itertools import combinations
            n_comp = len(list(combinations(range(len(groupes)), 2)))
            alpha_adj = alpha / n_comp
            
            for (i, j) in combinations(range(len(groupes)), 2):
                stat_mw, p_mw = stats.mannwhitneyu(groupes[i], groupes[j])
                sig = "***" if p_mw < alpha_adj else "n.s."
                print(f"{noms[i]} vs {noms[j]}: U={stat_mw:.1f}, p={p_mw:.4f} {sig}")
        else:
            print("‚Üí Pas de diff√©rences significatives")
    
    print("\n" + "=" * 60)

# Utilisation
rapport_nonparametrique(
    [agence_centre, agence_nord, agence_sud],
    ['Centre', 'Nord', 'Sud']
)
```

---

## R√©sum√© Express: Questions Probables

1. **"Quand utiliser Mann-Whitney au lieu du t-test?"**
   ‚Üí Quand la normalit√© n'est pas respect√©e ou donn√©es ordinales

2. **"Quelle est la diff√©rence entre Spearman et Pearson?"**
   ‚Üí Pearson: relation lin√©aire, Spearman: relation monotone (bas√© sur les rangs)

3. **"Comment interpr√©ter le test de Kruskal-Wallis?"**
   ‚Üí Alternative √† l'ANOVA, si p < 0.05 ‚Üí au moins un groupe diff√®re

4. **"Quand utiliser le test de Wilcoxon?"**
   ‚Üí Donn√©es appari√©es (avant/apr√®s) non normales

5. **"Qu'est-ce que le V de Cramer?"**
   ‚Üí Mesure de taille d'effet pour le Chi-carr√© (0 = pas d'association, 1 = association parfaite)

---

## Checklist Tests Non-Param√©triques

```
‚ñ° V√©rifier la normalit√© (Shapiro-Wilk)
‚ñ° Si p < 0.05 ou donn√©es ordinales ‚Üí non-param√©trique
‚ñ° Identifier le design:
  ‚ñ° 2 groupes ind√©p. ‚Üí Mann-Whitney
  ‚ñ° 2 groupes appari√©s ‚Üí Wilcoxon
  ‚ñ° 3+ groupes ind√©p. ‚Üí Kruskal-Wallis + post-hoc
  ‚ñ° 3+ groupes appari√©s ‚Üí Friedman + post-hoc
  ‚ñ° Corr√©lation ‚Üí Spearman
  ‚ñ° Association cat√©gorielle ‚Üí Chi-carr√©
‚ñ° Calculer la taille d'effet
‚ñ° Appliquer correction de Bonferroni si comparaisons multiples
‚ñ° Interpr√©ter dans le contexte bancaire
```

---

*Document pr√©par√© pour l'examen Data Analyst - UniBank Haiti*
*Tests Non-Param√©triques: L'alternative robuste*
