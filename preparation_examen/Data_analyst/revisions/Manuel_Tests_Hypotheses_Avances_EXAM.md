# MANUEL TESTS D'HYPOTH√àSES AVANC√âS - VERSION EXAMEN
## Data Analyst DPO - UniBank Haiti
### Concepts, D√©cisions, Sc√©narios Banking

---

## TABLE DES MATI√àRES

1. [Puissance Statistique et Taille d'Effet](#1-puissance-statistique-et-taille-deffet)
2. [Tests Post-Hoc D√©taill√©s](#2-tests-post-hoc-d√©taill√©s)
3. [Ajustements pour Comparaisons Multiples](#3-ajustements-pour-comparaisons-multiples)
4. [Tests Exacts](#4-tests-exacts)
5. [Analyse de Survie (Bases)](#5-analyse-de-survie-bases)
6. [Corr√©lation Partielle](#6-corr√©lation-partielle)
7. [R√©gression Logistique Simple](#7-r√©gression-logistique-simple)

---

## 1. PUISSANCE STATISTIQUE ET TAILLE D'EFFET

### 1.1 Les 4 √âl√©ments Interconnect√©s

```
Œ± (Seuil) ‚Üê‚Üí Puissance (1-Œ≤)
    ‚Üï             ‚Üï
Taille √©chantillon (n) ‚Üê‚Üí Taille d'effet (Œ¥)
```

#### Relations
- **Augmenter n** ‚Üí Augmente puissance
- **Augmenter Œ±** ‚Üí Augmente puissance (mais plus de faux positifs)
- **Effet plus grand** ‚Üí Augmente puissance
- **Puissance standard**: 80% (0.80)

---

### 1.2 Puissance Statistique (1-Œ≤)

#### D√©finition
> Probabilit√© de D√âTECTER un vrai effet quand il existe

#### Formule Intuitive
```
Puissance = P(Rejeter H‚ÇÄ | H‚ÇÅ vraie)
         = 1 - Œ≤ (erreur Type II)
```

#### Interpr√©tation par Valeur
```
Puissance < 50%: Tr√®s faible (comme lancer pi√®ce)
50-70%: Faible
70-80%: Acceptable
80-90%: Bon
> 90%: Excellent
```

#### Exemple Banking

**Contexte**: D√©tecter diff√©rence de 2% dans taux de d√©faut

```
Baseline: 5%
Effet attendu: +2% (donc 7%)

Si puissance = 80%:
‚Üí 80% de chances de d√©tecter cette diff√©rence SI elle existe
‚Üí 20% de risque de la manquer (erreur Type II)
```

---

### 1.3 Taille d'Effet (Effect Size)

#### Pourquoi Important?

**Significativit√© statistique ‚â† Importance pratique**

```
Exemple 1: n=10,000
Diff√©rence: 100 HTG sur solde moyen de 100,000 HTG
p = 0.001 (TR√àS significatif)
Mais 0.1% de diff√©rence = N√âGLIGEABLE pratiquement

Exemple 2: n=20
Diff√©rence: 10,000 HTG sur solde moyen de 50,000 HTG
p = 0.15 (NON significatif)
Mais 20% de diff√©rence = IMPORTANTE pratiquement
```

#### Cohen's d (Diff√©rence de Moyennes)

**Formule**:
```
d = (xÃÑ‚ÇÅ - xÃÑ‚ÇÇ) / s_pooled

O√π s_pooled = ‚àö[(s‚ÇÅ¬≤ + s‚ÇÇ¬≤) / 2]
```

**Interpr√©tation**:
```
|d| < 0.2: Effet N√âGLIGEABLE
0.2 ‚â§ |d| < 0.5: Effet FAIBLE
0.5 ‚â§ |d| < 0.8: Effet MOD√âR√â
|d| ‚â• 0.8: Effet FORT
```

**Exemple**:
```
Groupe A: xÃÑ = 50,000 HTG, s = 10,000
Groupe B: xÃÑ = 55,000 HTG, s = 12,000

d = (55,000 - 50,000) / ‚àö[(10,000¬≤ + 12,000¬≤)/2]
d = 5,000 / ‚àö(122,000,000)
d = 5,000 / 11,045
d = 0.45 (Effet FAIBLE √† MOD√âR√â)
```

---

#### Omega¬≤ (ANOVA)

**D√©finition**: Proportion de variance expliqu√©e par le facteur

**Formule**:
```
œâ¬≤ = (SSB - (k-1)√óMSW) / (SST + MSW)

O√π:
SSB = Somme carr√©s ENTRE
SST = Somme carr√©s TOTALE
MSW = Moyenne carr√©s √Ä L'INT√âRIEUR
k = Nombre de groupes
```

**Interpr√©tation**:
```
œâ¬≤ < 0.01: Effet n√©gligeable
0.01 ‚â§ œâ¬≤ < 0.06: Effet faible
0.06 ‚â§ œâ¬≤ < 0.14: Effet mod√©r√©
œâ¬≤ ‚â• 0.14: Effet fort
```

---

#### Phi (œÜ) pour Chi-Carr√©

**Formule (table 2√ó2)**:
```
œÜ = ‚àö(œá¬≤ / n)
```

**Interpr√©tation**:
```
|œÜ| < 0.1: Association n√©gligeable
0.1 ‚â§ |œÜ| < 0.3: Association faible
0.3 ‚â§ |œÜ| < 0.5: Association mod√©r√©e
|œÜ| ‚â• 0.5: Association forte
```

---

### 1.4 Calcul de la Puissance

#### Formule Approximative (Test t)

```
Puissance ‚âà Œ¶[Œ¥‚àö(n/2) - Z_(Œ±/2)]

O√π:
Œ¥ = Taille d'effet (Cohen's d)
n = Taille TOTALE √©chantillon
Œ¶ = Fonction distribution normale
Z_(Œ±/2) = Valeur critique (1.96 pour Œ±=0.05 bilat√©ral)
```

#### Exemple Pratique

**Question**: Quelle puissance pour d√©tecter d=0.5 avec n=100 par groupe?

```
Œ¥ = 0.5
n_total = 200
Œ± = 0.05 (bilat√©ral) ‚Üí Z = 1.96

Puissance ‚âà Œ¶[0.5 √ó ‚àö(200/2) - 1.96]
         ‚âà Œ¶[0.5 √ó 10 - 1.96]
         ‚âà Œ¶[5 - 1.96]
         ‚âà Œ¶[3.04]
         ‚âà 0.998 (99.8%)
```

**Conclusion**: Excellente puissance! On d√©tectera presque certainement un effet d=0.5.

---

### 1.5 Calcul Taille d'√âchantillon N√©cessaire

#### Formule (Test t, 2 groupes)

```
n = 2 √ó [(Z_Œ±/2 + Z_Œ≤) / Œ¥]¬≤

O√π:
Z_Œ±/2 = 1.96 (pour Œ±=0.05 bilat√©ral)
Z_Œ≤ = 0.84 (pour puissance 80%)
Œ¥ = Taille d'effet (Cohen's d)
```

#### Exemple Banking

**Question**: Combien de clients pour d√©tecter diff√©rence de 5,000 HTG (d=0.5) avec 80% de puissance?

```
n = 2 √ó [(1.96 + 0.84) / 0.5]¬≤
n = 2 √ó [2.8 / 0.5]¬≤
n = 2 √ó [5.6]¬≤
n = 2 √ó 31.36
n = 62.72 ‚âà 63 par groupe
n_total = 126 clients
```

---

### 1.6 Sc√©nario Banking Complet

**Contexte DPO**: Tester nouvelle campagne anti-fraude

**Donn√©es Actuelles**:
- Taux fraude actuel: 2%
- Objectif campagne: R√©duire √† 1% (MDE = 1%)

**Question 1**: Quelle taille d'√©chantillon pour 80% de puissance?

```
p‚ÇÅ = 0.02, p‚ÇÇ = 0.01
Œ¥ = |p‚ÇÅ - p‚ÇÇ| = 0.01
pÃÑ = (0.02 + 0.01)/2 = 0.015

n ‚âà 2 √ó [(1.96 + 0.84)¬≤ √ó pÃÑ(1-pÃÑ)] / Œ¥¬≤
n ‚âà 2 √ó [7.84 √ó 0.015 √ó 0.985] / 0.0001
n ‚âà 2,309 transactions par groupe
n_total ‚âà 4,618 transactions minimum
```

**Question 2**: Avec seulement 1,000 par groupe, quelle puissance?

```
Puissance ‚âà 40% (insuffisant!)
```

**D√©cision Business**:
- Option A: Collecter plus de donn√©es (4,618 minimum)
- Option B: Accepter puissance r√©duite (risque manquer l'effet)
- Option C: Allonger dur√©e test pour atteindre n n√©cessaire

---

## 2. TESTS POST-HOC D√âTAILL√âS

### 2.1 Pourquoi Post-Hoc?

#### Probl√®me
ANOVA dit "au moins une diff√©rence" mais ne dit PAS laquelle!

```
Exemple: 4 agences
ANOVA: F=8.5, p=0.001 ‚Üí Au moins 1 diff√©rence

Mais quelles paires diff√®rent?
Nord-Sud? Nord-Est? Nord-Ouest?
Sud-Est? Sud-Ouest? Est-Ouest?
‚Üí 6 comparaisons possibles!
```

---

### 2.2 Test de Tukey HSD (Honestly Significant Difference)

#### Quand Utiliser
- Apr√®s ANOVA significative
- Comparer TOUTES les paires
- √âchantillons de tailles √©gales

#### Formule
```
HSD = q_Œ± √ó ‚àö(MSW / n)

O√π:
q_Œ± = Valeur de Tukey (table)
MSW = Moyenne carr√©s √Ä L'INT√âRIEUR (de l'ANOVA)
n = Taille commune des groupes
```

#### R√®gle de D√©cision
```
Si |xÃÑ·µ¢ - xÃÑ‚±º| > HSD ‚Üí Diff√©rence significative
```

#### Exemple Banking

**Contexte**: Comparer soldes moyens entre 4 agences (n=30 chacune)

**R√©sultats ANOVA**:
```
Nord: 25,000 HTG
Sud:  30,000 HTG
Est:  28,000 HTG
Ouest: 32,000 HTG

MSW = 25,000,000 HTG¬≤
F = 8.45, p < 0.001
```

**Calcul HSD**:
```
q(0.05, 4, 116) ‚âà 3.70
HSD = 3.70 √ó ‚àö(25,000,000 / 30)
HSD = 3.70 √ó 913
HSD = 3,378 HTG
```

**Comparaisons**:
```
Nord-Sud:  |25K-30K| = 5,000 > 3,378 ‚úì SIGNIFICATIF
Nord-Est:  |25K-28K| = 3,000 < 3,378 ‚úó Non significatif
Nord-Ouest:|25K-32K| = 7,000 > 3,378 ‚úì SIGNIFICATIF
Sud-Est:   |30K-28K| = 2,000 < 3,378 ‚úó Non significatif
Sud-Ouest: |30K-32K| = 2,000 < 3,378 ‚úó Non significatif
Est-Ouest: |28K-32K| = 4,000 > 3,378 ‚úì SIGNIFICATIF
```

**Conclusion**:
- Nord diff√®re de Sud ET Ouest
- Est diff√®re de Ouest
- Les autres paires ne diff√®rent pas significativement

**Graphique Mental**:
```
Groupes Homog√®nes:
Groupe A: Nord
Groupe B: Est, Sud
Groupe C: Sud, Ouest
```

---

### 2.3 Test de Bonferroni

#### Principe
Ajuster Œ± pour chaque comparaison

#### Formule
```
Œ±_ajust√© = Œ± / m

O√π m = nombre de comparaisons
```

#### Quand Utiliser
- Peu de comparaisons planifi√©es (< 10)
- Veut minimiser Erreur Type I

#### Exemple

**4 groupes ‚Üí 6 comparaisons possibles**
```
Œ±_original = 0.05
Œ±_ajust√© = 0.05 / 6 = 0.0083

Utiliser Œ±=0.0083 pour chaque test t individuel
```

**Avantage**: Tr√®s conservateur (peu de faux positifs)  
**Inconv√©nient**: Perd de la puissance (peut manquer vrais effets)

---

### 2.4 Test de Scheff√©

#### Quand Utiliser
- Comparaisons complexes (ex: A+B vs C+D)
- Apr√®s coup (non planifi√©)

#### Formule
```
S = ‚àö[(k-1) √ó F_critique]

Diff√©rence significative si:
|Contraste| > S √ó ‚àö(MSW √ó Œ£(c¬≤·µ¢/n·µ¢))
```

**Avantage**: Le plus flexible (tout type de comparaison)  
**Inconv√©nient**: Le plus conservateur (moins de puissance)

---

### 2.5 Test de Dunn (Post-hoc pour Kruskal-Wallis)

#### Quand Utiliser
Apr√®s Kruskal-Wallis significatif (version non-param√©trique)

#### Principe
Compare rangs moyens entre paires, avec ajustement Bonferroni

#### Exemple

**Contexte**: Satisfaction (ordinal) entre 3 segments

**R√©sultats Kruskal-Wallis**:
```
H = 12.5, p = 0.002
‚Üí Au moins une diff√©rence
```

**Test de Dunn**:
```
Premium vs Standard: p_ajust√© = 0.001 ‚úì
Premium vs Bronze:   p_ajust√© = 0.008 ‚úì
Standard vs Bronze:  p_ajust√© = 0.15  ‚úó
```

---

## 3. AJUSTEMENTS POUR COMPARAISONS MULTIPLES

### 3.1 Probl√®me du Multiple Testing

#### Inflation de l'Erreur Type I

**Principe**:
```
Pour 1 test: P(Erreur Type I) = Œ± = 0.05 (5%)

Pour m tests ind√©pendants:
P(Au moins 1 erreur) = 1 - (1-Œ±)^m

Exemples:
m=5:  1 - 0.95‚Åµ = 0.226 (22.6%)
m=10: 1 - 0.95¬π‚Å∞ = 0.401 (40.1%)
m=20: 1 - 0.95¬≤‚Å∞ = 0.642 (64.2%)
```

**Danger**: Plus on teste, plus on trouve de "faux positifs"!

---

### 3.2 M√©thodes de Correction

#### Tableau Comparatif

| M√©thode | Œ±_ajust√© | Puissance | Quand utiliser |
|---------|----------|-----------|----------------|
| **Bonferroni** | Œ±/m | Faible | Peu de tests (<10), tests planifi√©s |
| **Holm** | Œ±/(m-i+1) | Moyenne | Alternative √† Bonferroni |
| **Benjamini-Hochberg** | (i/m)√óŒ± | √âlev√©e | Beaucoup de tests, exploration |

---

#### M√©thode de Bonferroni

**Formule**:
```
Œ±_ajust√© = Œ± / m
```

**Exemple Banking**:
```
Tester 10 KPIs bancaires
Œ± = 0.05
Œ±_ajust√© = 0.05 / 10 = 0.005

Rejeter H‚ÇÄ seulement si p < 0.005
```

**Avantage**: Simple, tr√®s conservateur  
**Inconv√©nient**: Peut manquer vrais effets (perte de puissance)

---

#### M√©thode de Holm (Sequential Bonferroni)

**Proc√©dure**:
1. Ordonner p-values: p‚ÇÅ ‚â§ p‚ÇÇ ‚â§ ... ‚â§ p‚Çò
2. Comparer:
   - p‚ÇÅ < Œ±/m ?
   - p‚ÇÇ < Œ±/(m-1) ?
   - p‚ÇÉ < Œ±/(m-2) ?
   - Continuer jusqu'au premier NON

**Exemple**:
```
5 tests, Œ±=0.05
p-values: 0.001, 0.008, 0.015, 0.03, 0.06

Test 1: 0.001 < 0.05/5 = 0.01 ‚úì Rejeter
Test 2: 0.008 < 0.05/4 = 0.0125 ‚úì Rejeter
Test 3: 0.015 < 0.05/3 = 0.0167 ‚úì Rejeter
Test 4: 0.03 < 0.05/2 = 0.025 ‚úó STOP ici
Test 5: Non test√©

Conclusion: Tests 1, 2, 3 significatifs
```

**Avantage**: Plus puissant que Bonferroni  
**Inconv√©nient**: Plus complexe

---

#### M√©thode de Benjamini-Hochberg (FDR)

**Principe**: Contr√¥le le taux de Fausses D√©couvertes (False Discovery Rate)

**Proc√©dure**:
1. Ordonner p-values: p‚ÇÅ ‚â§ p‚ÇÇ ‚â§ ... ‚â§ p‚Çò
2. Trouver le plus grand i tel que: p·µ¢ ‚â§ (i/m) √ó Œ±
3. Rejeter H‚ÇÄ pour tests 1, 2, ..., i

**Exemple**:
```
10 tests, Œ±=0.05
p-values ordonn√©es:
p‚ÇÅ=0.001, p‚ÇÇ=0.003, p‚ÇÉ=0.008, p‚ÇÑ=0.012,
p‚ÇÖ=0.025, p‚ÇÜ=0.04, p‚Çá=0.06, p‚Çà=0.08,
p‚Çâ=0.15, p‚ÇÅ‚ÇÄ=0.30

V√©rification:
i=1: 0.001 ‚â§ (1/10)√ó0.05 = 0.005 ‚úì
i=2: 0.003 ‚â§ (2/10)√ó0.05 = 0.01 ‚úì
i=3: 0.008 ‚â§ (3/10)√ó0.05 = 0.015 ‚úì
i=4: 0.012 ‚â§ (4/10)√ó0.05 = 0.02 ‚úì
i=5: 0.025 ‚â§ (5/10)√ó0.05 = 0.025 ‚úì
i=6: 0.04 ‚â§ (6/10)√ó0.05 = 0.03 ‚úó

Plus grand i = 5
‚Üí Rejeter tests 1, 2, 3, 4, 5
```

**Avantage**: Le plus puissant, bon pour exploration  
**Inconv√©nient**: Accepte plus de faux positifs (contr√¥le FDR, pas FWER)

---

### 3.3 Sc√©nario Banking: A/B/C/D Test

**Contexte**: Tester 4 versions d'email marketing

**Donn√©es**:
| Version | Conversions | Total | Taux | p-value vs A |
|---------|-------------|-------|------|--------------|
| A (contr√¥le) | 100 | 1000 | 10% | - |
| B | 120 | 1000 | 12% | 0.03 |
| C | 130 | 1000 | 13% | 0.01 |
| D | 105 | 1000 | 10.5% | 0.45 |

**Sans correction**:
```
B et C significatifs √† Œ±=0.05
```

**Avec Bonferroni** (3 comparaisons):
```
Œ±_ajust√© = 0.05/3 = 0.0167

B: 0.03 > 0.0167 ‚úó Non significatif
C: 0.01 < 0.0167 ‚úì Significatif
D: 0.45 > 0.0167 ‚úó Non significatif

‚Üí Seule version C significativement meilleure
```

**D√©cision Business**: D√©ployer version C, elle surperforme significativement le contr√¥le (+30% conversion).

---

## 4. TESTS EXACTS

### 4.1 Test Exact de Fisher

#### Quand Utiliser
- Table 2√ó2
- Effectifs PETITS (attendus < 5)
- Alternative EXACTE au Chi-carr√©

#### Principe
Calcule probabilit√© EXACTE (pas approximation)

#### Formule
```
p = (a+b)!(c+d)!(a+c)!(b+d)! / (n! √ó a! √ó b! √ó c! √ó d!)

Pour table:
        Y    N
Expos√©  a    b
Non-exp c    d
```

#### Exemple Banking

**Contexte**: Test fraude sur petit √©chantillon

**Donn√©es**:
|          | Fraude | Pas Fraude | Total |
|----------|--------|------------|-------|
| Nouveau  | 3      | 7          | 10    |
| Ancien   | 1      | 14         | 15    |
| **Total**| 4      | 21         | 25    |

**Chi-carr√©**: Attendu = (10√ó4)/25 = 1.6 < 5 ‚Üí PAS VALIDE

**Test Exact de Fisher**:
```
p_exact = 0.31

Conclusion: Pas de diff√©rence significative entre nouveaux et anciens clients
```

---

### 4.2 Test Binomial Exact

#### Quand Utiliser
- Tester UNE proportion
- Petit √©chantillon (n < 30)
- Alternative exacte au test Z

#### Principe
Utilise distribution binomiale (pas approximation normale)

#### Exemple Banking

**Contexte**: Sur 15 dossiers audit√©s, 5 ont des erreurs (33%). Le taux acceptable est 20%.

**Test Binomial Exact**:
```
H‚ÇÄ: p = 0.20
H‚ÇÅ: p > 0.20

p_exact = P(X ‚â• 5 | n=15, p=0.20)
p_exact = 0.188

Conclusion: p = 0.188 > 0.05
Ne peut pas conclure taux anormalement √©lev√©
```

**Comparaison Test Z** (pour montrer diff√©rence):
```
Test Z donnerait p ‚âà 0.15 (moins pr√©cis avec petit n)
```

---

## 5. ANALYSE DE SURVIE (BASES)

### 5.1 Concepts Fondamentaux

#### D√©finition
Analyse du TEMPS jusqu'√† un √©v√©nement

#### Applications Banking
- Temps jusqu'√† d√©faut de paiement
- Dur√©e de vie d'un compte
- Temps avant churn client
- D√©lai avant activation produit

#### Caract√©ristiques Uniques
1. **Censure**: Observations incompl√®tes (ex: client n'a pas encore quitt√© √† la fin de l'√©tude)
2. **Temps d'observation variable**
3. **√âv√©nement binaire** (arriv√© ou non)

---

### 5.2 Fonction de Survie S(t)

#### D√©finition
```
S(t) = P(T > t) = Probabilit√© de survivre au-del√† du temps t
```

#### Propri√©t√©s
```
S(0) = 1 (tous "vivants" au d√©but)
S(‚àû) = 0 (tous "morts" √©ventuellement)
Fonction d√©croissante
```

#### Exemple Banking

**Contexte**: Survie des comptes (temps avant fermeture)

```
S(3 mois) = 0.95 ‚Üí 95% des comptes actifs apr√®s 3 mois
S(12 mois) = 0.80 ‚Üí 80% actifs apr√®s 1 an
S(24 mois) = 0.65 ‚Üí 65% actifs apr√®s 2 ans
```

---

### 5.3 Estimateur de Kaplan-Meier

#### Principe
Estime S(t) en tenant compte de la censure

#### Formule
```
S(t) = ‚àè[1 - (d·µ¢/n·µ¢)]

Pour tous i o√π t·µ¢ ‚â§ t

O√π:
d·µ¢ = Nombre d'√©v√©nements au temps t·µ¢
n·µ¢ = Nombre √† risque juste avant t·µ¢
```

#### Exemple Banking Simplifi√©

**Contexte**: Survie de 10 pr√™ts (temps jusqu'√† d√©faut)

**Donn√©es**:
```
Pr√™t 1: D√©faut mois 3
Pr√™t 2: Censur√© mois 5 (rembours√©)
Pr√™t 3: D√©faut mois 6
Pr√™t 4: Actif mois 12 (fin √©tude)
Pr√™t 5: D√©faut mois 3
...
```

**Calcul**:
```
Temps 3 mois:
- 2 d√©fauts
- 10 √† risque
- S(3) = 1 √ó (1 - 2/10) = 0.80

Temps 6 mois:
- 1 d√©faut
- 7 √† risque (10 - 2 d√©fauts - 1 censur√©)
- S(6) = 0.80 √ó (1 - 1/7) = 0.686

‚Üí 68.6% des pr√™ts survivent 6 mois
```

---

### 5.4 Test du Log-Rank

#### D√©finition
Compare courbes de survie entre DEUX groupes

#### Quand Utiliser
- Comparer temps de survie entre 2 segments
- Exemple: D√©faut Premium vs Standard

#### Hypoth√®ses
```
H‚ÇÄ: Les courbes de survie sont identiques
H‚ÇÅ: Les courbes diff√®rent
```

#### Principe
Compare nombre d'√©v√©nements OBSERV√âS vs ATTENDUS √† chaque temps

#### Exemple Banking

**Contexte**: Comparer d√©faut entre Anciens vs Nouveaux clients

**R√©sultats**:
```
Log-Rank œá¬≤ = 8.45
p-value = 0.004

Conclusion: Les courbes de survie diff√®rent significativement
‚Üí Nouveaux clients ont taux de d√©faut plus √©lev√©
```

**Graphique Mental**:
```
Survie
100% ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
           ‚îÇ Anciens (meilleure survie)
 80% ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îê
           ‚îÇ    ‚îÇ
 60% ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ Nouveaux
           ‚îÇ    ‚îÇ
 40% ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ
     0   6   12  18 Mois
```

---

### 5.5 Temps M√©dian de Survie

#### D√©finition
Temps auquel S(t) = 0.50 (50% ont connu l'√©v√©nement)

#### Calcul
Trouver t tel que S(t) = 0.50

#### Exemple

**Contexte**: Dur√©e moyenne avant churn

```
S(6 mois) = 0.75
S(12 mois) = 0.45
S(18 mois) = 0.30

Temps m√©dian ‚âà 11 mois (interpolation)
‚Üí 50% des clients partent avant 11 mois
```

**Interpr√©tation Business**:
- Temps critique = 11 mois
- Programme r√©tention √† cibler √† 9-10 mois

---

## 6. CORR√âLATION PARTIELLE

### 6.1 D√©finition

#### Principe
Corr√©lation entre X et Y APR√àS avoir retir√© l'effet d'une variable Z

```
Corr√©lation Partielle r(X,Y|Z) = Corr√©lation entre:
- R√©sidus de X apr√®s r√©gression sur Z
- R√©sidus de Y apr√®s r√©gression sur Z
```

#### Pourquoi Important?

**Exemple**: Corr√©lation glace ‚Üî noyades

```
Corr√©lation simple: r = 0.8 (forte!)
Mais variable cach√©e: Temp√©rature

Corr√©lation partielle (contr√¥lant temp√©rature): r = 0.05 (n√©gligeable)
‚Üí La temp√©rature EXPLIQUE la corr√©lation apparente
```

---

### 6.2 Formule

```
r(X,Y|Z) = (r_XY - r_XZ √ó r_YZ) / ‚àö[(1-r¬≤_XZ) √ó (1-r¬≤_YZ)]

O√π:
r_XY = Corr√©lation simple X-Y
r_XZ = Corr√©lation simple X-Z
r_YZ = Corr√©lation simple Y-Z
```

---

### 6.3 Exemple Banking Complet

**Contexte DPO**: Analyser relation Solde ‚Üî Nombre Transactions

**Hypoth√®se**: Variable cach√©e = Anciennet√© client

**Donn√©es**:
```
r(Solde, Transactions) = 0.65 (forte corr√©lation)
r(Solde, Anciennet√©) = 0.70
r(Transactions, Anciennet√©) = 0.75
```

**Calcul Corr√©lation Partielle**:
```
r(Solde, Trans | Anciennet√©) = (0.65 - 0.70√ó0.75) / ‚àö[(1-0.70¬≤)√ó(1-0.75¬≤)]
                               = (0.65 - 0.525) / ‚àö[0.51 √ó 0.4375]
                               = 0.125 / ‚àö0.223
                               = 0.125 / 0.472
                               = 0.26
```

**Interpr√©tation**:
```
Corr√©lation simple: 0.65 (forte)
Corr√©lation partielle: 0.26 (faible)

‚Üí La relation Solde-Transactions est LARGEMENT due √† l'anciennet√©
‚Üí Clients anciens ont + de solde ET + de transactions
‚Üí Contr√¥ler anciennet√© r√©duit fortement la corr√©lation
```

**D√©cision Business**:
- Ne pas baser strat√©gie sur corr√©lation simple Solde-Transactions
- Segmenter par anciennet√© d'abord
- Analyser patterns DANS chaque segment d'anciennet√©

---

### 6.4 Sc√©nario: Variable de Confusion

**Contexte**: Relation Score Cr√©dit ‚Üî Montant Pr√™t

**Observation Initiale**:
```
r(Score, Montant) = 0.80 (forte)
Conclusion na√Øve: Score √©lev√© ‚Üí Gros pr√™ts
```

**Variable Cach√©e**: Revenu

**Analyse**:
```
r(Score, Revenu) = 0.85
r(Montant, Revenu) = 0.90

Corr√©lation partielle:
r(Score, Montant | Revenu) = 0.15 (faible!)
```

**V√©rit√©**:
- Revenu √âLEV√â ‚Üí Score √âLEV√â (peuvent rembourser)
- Revenu √âLEV√â ‚Üí Pr√™t √âLEV√â (capacit√© emprunt)
- Relation directe Score-Montant est FAIBLE

**Impact**: Mod√®le de scoring doit inclure REVENU explicitement

---

## 7. R√âGRESSION LOGISTIQUE SIMPLE

### 7.1 Principe

#### Diff√©rence avec R√©gression Lin√©aire

```
R√©gression Lin√©aire:
Y continue = Œ≤‚ÇÄ + Œ≤‚ÇÅX + Œµ

R√©gression Logistique:
Y binaire (0/1) ‚Üí P(Y=1) = ?
```

#### Fonction Logit
```
logit(p) = ln[p/(1-p)] = Œ≤‚ÇÄ + Œ≤‚ÇÅX

O√π:
p = P(Y=1)
p/(1-p) = Odds
```

#### Transformation Inverse
```
p = e^(Œ≤‚ÇÄ+Œ≤‚ÇÅX) / (1 + e^(Œ≤‚ÇÄ+Œ≤‚ÇÅX))
```

---

### 7.2 Interpr√©tation des Coefficients

#### Coefficient Œ≤‚ÇÅ

```
exp(Œ≤‚ÇÅ) = Odds Ratio (OR)
```

**Interpr√©tation**:
```
OR = 1: X n'a pas d'effet
OR > 1: Augmentation de X augmente probabilit√© Y=1
OR < 1: Augmentation de X diminue probabilit√© Y=1
```

#### Exemple Banking

**Mod√®le**: Pr√©dire D√©faut en fonction du Score

```
logit(P_d√©faut) = 5 - 0.01 √ó Score

Œ≤‚ÇÅ = -0.01
OR = exp(-0.01) = 0.990

Interpr√©tation:
Pour chaque point de score suppl√©mentaire,
l'odds de d√©faut diminue de 1% (√ó0.99)
```

**Calcul Pratique**:
```
Score 600:
logit = 5 - 0.01√ó600 = -1
P = e^(-1) / (1+e^(-1)) = 0.27 (27% d√©faut)

Score 700:
logit = 5 - 0.01√ó700 = -2
P = e^(-2) / (1+e^(-2)) = 0.12 (12% d√©faut)
```

---

### 7.3 Exemple Complet: Mod√®le D√©faut

**Contexte DPO**: Pr√©dire d√©faut avec Score et Ratio Dette/Revenu

**Mod√®le**:
```
logit(P_d√©faut) = 3 - 0.008√óScore + 2√óRatioDette
```

**Coefficients**:
```
Intercept: Œ≤‚ÇÄ = 3
Score: Œ≤‚ÇÅ = -0.008 ‚Üí OR = exp(-0.008) = 0.992
RatioDette: Œ≤‚ÇÇ = 2 ‚Üí OR = exp(2) = 7.39
```

**Interpr√©tation**:
1. **Score**: +1 point ‚Üí Odds d√©faut √ó0.992 (‚Üì0.8%)
2. **RatioDette**: +0.1 (10%) ‚Üí Odds d√©faut √óe^(2√ó0.1) = √ó1.22 (‚Üë22%)

**Pr√©diction Client Type**:
```
Score = 650
RatioDette = 0.4 (40%)

logit = 3 - 0.008√ó650 + 2√ó0.4
      = 3 - 5.2 + 0.8
      = -1.4

P_d√©faut = e^(-1.4) / (1+e^(-1.4))
         = 0.198 (19.8%)
```

**D√©cision Cr√©dit**:
```
Seuil acceptable: 15%
P_observ√©: 19.8%
‚Üí REFUSER le pr√™t (risque trop √©lev√©)
```

---

### 7.4 Test de Significativit√©

#### Test de Wald

**Hypoth√®ses**:
```
H‚ÇÄ: Œ≤·µ¢ = 0 (variable n'a pas d'effet)
H‚ÇÅ: Œ≤·µ¢ ‚â† 0
```

**Statistique**:
```
z = Œ≤ÃÇ·µ¢ / SE(Œ≤ÃÇ·µ¢)

Suit loi normale standard
```

**Exemple**:
```
Œ≤ÃÇ‚ÇÅ = -0.008
SE = 0.002

z = -0.008 / 0.002 = -4.0
p-value < 0.001

Conclusion: Score a effet SIGNIFICATIF
```

---

### 7.5 Qualit√© du Mod√®le

#### Pseudo R¬≤ (McFadden)

```
R¬≤_McFadden = 1 - (Log L_mod√®le / Log L_null)

Interpr√©tation:
> 0.2: Bon ajustement
> 0.4: Tr√®s bon
```

#### AIC (Akaike Information Criterion)

```
AIC = -2√óLog L + 2√ók

O√π k = nombre de param√®tres

Plus bas = Meilleur mod√®le
```

#### Courbe ROC et AUC

**AUC (Area Under Curve)**:
```
0.5: Pas mieux que hasard
0.7-0.8: Acceptable
0.8-0.9: Excellent
> 0.9: Exceptionnel
```

**Exemple Banking**:
```
Mod√®le D√©faut:
AUC = 0.85

Interpr√©tation: 85% de chances que mod√®le range
correctement paire (d√©faut, non-d√©faut)
‚Üí Excellent pouvoir pr√©dictif
```

---

### 7.6 Sc√©nario Complet: Mod√®le Approbation Cr√©dit

**Contexte**: Construire mod√®le approbation automatique

**Variables**:
- Score cr√©dit (600-850)
- Revenu annuel (HTG)
- Ratio Dette/Revenu (0-1)
- Anciennet√© emploi (ann√©es)

**Mod√®le Estim√©**:
```
logit(P_d√©faut) = 8.5
                  - 0.01√óScore
                  + 2.5√óRatioDette
                  - 0.0001√óRevenu
                  - 0.15√óAnciennet√©
```

**Tests de Significativit√©**:
```
Score: p < 0.001 ‚úì‚úì‚úì
RatioDette: p < 0.001 ‚úì‚úì‚úì
Revenu: p = 0.03 ‚úì
Anciennet√©: p = 0.18 ‚úó (Non significatif)
```

**D√©cision**: Retirer Anciennet√© du mod√®le

**Mod√®le Final**:
```
logit(P_d√©faut) = 8
                  - 0.01√óScore
                  + 2.5√óRatioDette
                  - 0.0001√óRevenu

AUC = 0.87 (Excellent)
```

**Seuils D√©cision**:
```
P_d√©faut < 5%: Approbation AUTO
5% ‚â§ P < 15%: Revue MANUELLE
P ‚â• 15%: Refus AUTO
```

**Application Client**:
```
Client A:
Score = 750
RatioDette = 0.25
Revenu = 500,000 HTG

logit = 8 - 0.01√ó750 + 2.5√ó0.25 - 0.0001√ó500,000
      = 8 - 7.5 + 0.625 - 50
      = -48.875

P = e^(-48.875) / (1 + e^(-48.875)) ‚âà 0 (0%)
‚Üí APPROBATION AUTOMATIQUE
```

---

## R√âSUM√â EX√âCUTIF

### Points Cl√©s √† Retenir

1. **Puissance Statistique**
   - Standard: 80%
   - Augmente avec n et taille d'effet
   - Calculer AVANT de collecter donn√©es

2. **Taille d'Effet**
   - Plus important que p-value
   - Cohen's d: <0.2 (faible), 0.2-0.8 (mod√©r√©), >0.8 (fort)
   - Toujours rapporter avec r√©sultats

3. **Tests Post-Hoc**
   - Tukey HSD: Toutes comparaisons, tailles √©gales
   - Bonferroni: Conservateur, peu de tests
   - Dunn: Pour Kruskal-Wallis

4. **Comparaisons Multiples**
   - Bonferroni: Œ±/m (tr√®s conservateur)
   - Holm: S√©quentiel (meilleur)
   - BH: FDR (plus puissant, exploration)

5. **Tests Exacts**
   - Fisher: Table 2√ó2, petits effectifs
   - Binomial: Proportion, petit n

6. **Analyse Survie**
   - Kaplan-Meier: Estimer S(t)
   - Log-Rank: Comparer courbes
   - Temps m√©dian: Quand 50% √©v√©nement

7. **Corr√©lation Partielle**
   - Retire effet variable de confusion
   - Peut r√©duire fortement corr√©lation simple
   - Essentiel pour causalit√©

8. **R√©gression Logistique**
   - Y binaire
   - OR = exp(Œ≤)
   - Pr√©diction: P(Y=1)
   - √âvaluer: AUC, Pseudo R¬≤

---

**TU ES PR√äT ALEXANDRO! üí™üî•**
