# MANUEL STATISTIQUES INFÃ‰RENTIELLES - VERSION EXAMEN Ã‰CRIT
## Data Analyst DPO - UniBank Haiti
### Format optimisÃ© pour rÃ©vision et examen manuscrit

---

## TABLE DES MATIÃˆRES

1. [Concepts Fondamentaux](#1-concepts-fondamentaux)
2. [Ã‰chantillonnage](#2-Ã©chantillonnage)
3. [Intervalles de Confiance](#3-intervalles-de-confiance)
4. [Tests d'HypothÃ¨ses - Vue d'Ensemble](#4-tests-dhypothÃ¨ses---vue-densemble)
5. [Test t de Student](#5-test-t-de-student)
6. [Test Z pour Proportions](#6-test-z-pour-proportions)
7. [Test du Chi-CarrÃ©](#7-test-du-chi-carrÃ©)
8. [ANOVA](#8-anova)
9. [Tests Non-ParamÃ©triques](#9-tests-non-paramÃ©triques)
10. [Arbres de DÃ©cision](#10-arbres-de-dÃ©cision)

---

## 1. CONCEPTS FONDAMENTAUX

### 1.1 Population vs Ã‰chantillon

#### DÃ©finitions
- **Population (N)**: Ensemble COMPLET de tous les Ã©lÃ©ments Ã©tudiÃ©s
- **Ã‰chantillon (n)**: Sous-ensemble REPRÃ‰SENTATIF de la population

#### Exemple Bancaire DPO
```
Population: Tous les clients UniBank (500,000)
Ã‰chantillon: 1,000 clients sÃ©lectionnÃ©s pour enquÃªte satisfaction
```

#### ParamÃ¨tres vs Statistiques

| Mesure | Population | Ã‰chantillon | Symbole |
|--------|-----------|-------------|---------|
| Moyenne | Î¼ (mu) | xÌ„ (x-bar) | Formule: Î£x/n |
| Ã‰cart-type | Ïƒ (sigma) | s | âˆš[Î£(x-Î¼)Â²/n] |
| Proportion | p | pÌ‚ (p-hat) | SuccÃ¨s/Total |

**Principe clÃ©:** On calcule des **statistiques** sur l'**Ã©chantillon** pour ESTIMER les **paramÃ¨tres** de la **population**.

---

### 1.2 Pourquoi Ã‰chantillonner?

#### Raisons Pratiques
1. **CoÃ»t**: Ã‰tudier 500K clients coÃ»terait des millions
2. **Temps**: Analyse complÃ¨te prendrait des annÃ©es
3. **Destructif**: Certains tests dÃ©truisent l'objet (audit approfondi)
4. **ImpossibilitÃ©**: Population infinie ou inaccessible

#### Exemple DPO UniBank
Au lieu d'auditer TOUS les dossiers de crÃ©dit (50,000), on en sÃ©lectionne 500 de maniÃ¨re alÃ©atoire pour dÃ©tecter les non-conformitÃ©s RGPD.

---

### 1.3 ThÃ©orÃ¨me Central Limite (TCL)

#### Ã‰noncÃ©
> Pour n â‰¥ 30, la distribution des moyennes d'Ã©chantillons tend vers une **distribution normale**, QUELLE QUE SOIT la distribution de la population.

#### Formule
```
Moyenne des Ã©chantillons: Î¼xÌ„ = Î¼
Erreur standard: ÏƒxÌ„ = Ïƒ / âˆšn
```

#### Implications Pratiques
1. Plus n augmente â†’ Plus l'estimation est prÃ©cise
2. Doubler la prÃ©cision â†’ Multiplier n par 4
3. Permet d'utiliser la loi normale pour l'infÃ©rence

#### Graphique Mental
```
Population        Ã‰chantillons (n=100)     Distribution des moyennes
(asymÃ©trique) â†’   Tirer 1000 fois    â†’    (NORMALE!)
    ___                                          /\
   /  |                                         /  \
  /   |__                                     /    \
```

---

## 2. Ã‰CHANTILLONNAGE

### 2.1 Types d'Ã‰chantillonnage

#### Ã‰chantillonnage Probabiliste (RecommandÃ©)

| MÃ©thode | Description | Quand utiliser | Exemple DPO |
|---------|-------------|----------------|-------------|
| **AlÃ©atoire Simple** | Chaque individu a mÃªme probabilitÃ© | Population homogÃ¨ne | Tirer 100 clients au hasard |
| **StratifiÃ©** | Diviser en groupes, puis Ã©chantillonner | Population hÃ©tÃ©rogÃ¨ne | 50 clients par agence |
| **Par Grappes** | SÃ©lectionner des groupes entiers | RÃ©duire coÃ»ts gÃ©ographiques | SÃ©lectionner 5 agences complÃ¨tes |
| **SystÃ©matique** | SÃ©lection Ã  intervalle rÃ©gulier | Liste ordonnÃ©e disponible | Chaque 50Ã¨me transaction |

#### Ã‰chantillonnage Non-Probabiliste (Ã€ Ã©viter)
- **Convenance**: Prendre ce qui est facile (BIAIS!)
- **Quota**: Remplir des quotas arbitraires
- **Jugement**: Expert choisit (SUBJECTIF!)

### 2.2 Taille d'Ã‰chantillon

#### Formule GÃ©nÃ©rale (Proportion)
```
n = ZÂ² Ã— p(1-p) / EÂ²

OÃ¹:
- Z = Score Z pour niveau de confiance (1.96 pour 95%)
- p = Proportion estimÃ©e (0.5 si inconnue)
- E = Marge d'erreur dÃ©sirÃ©e
```

#### Exemple CalculÃ©
**Objectif**: Estimer le taux de dÃ©faut avec marge d'erreur Â±3% et 95% de confiance

```
n = (1.96)Â² Ã— 0.5(1-0.5) / (0.03)Â²
n = 3.84 Ã— 0.25 / 0.0009
n = 1067 clients minimum
```

#### RÃ¨gle Pratique
- **n â‰¥ 30**: Minimum absolu pour TCL
- **n â‰¥ 100**: Bon pour estimations
- **n â‰¥ 1000**: Excellent pour prÃ©cision fine

---

## 3. INTERVALLES DE CONFIANCE

### 3.1 DÃ©finition

**Intervalle de Confiance (IC)**: Plage de valeurs oÃ¹ se trouve le VRAI paramÃ¨tre avec un certain niveau de confiance.

#### InterprÃ©tation CORRECTE
"On est confiant Ã  95% que le VRAI taux de dÃ©faut se situe entre 4% et 6%"

#### InterprÃ©tation INCORRECTE (Ne JAMAIS dire)
âŒ "Il y a 95% de chances que le taux soit entre 4% et 6%"  
Le paramÃ¨tre est FIXE, c'est notre ESTIMATION qui varie!

### 3.2 Formules par Type

#### IC pour une Moyenne (n â‰¥ 30)
```
IC = xÌ„ Â± Z Ã— (s / âˆšn)

OÃ¹:
- xÌ„ = Moyenne Ã©chantillon
- Z = 1.96 (pour 95%), 1.645 (pour 90%), 2.576 (pour 99%)
- s = Ã‰cart-type Ã©chantillon
- n = Taille Ã©chantillon
```

#### IC pour une Moyenne (n < 30)
```
IC = xÌ„ Â± t Ã— (s / âˆšn)

Utiliser table t de Student avec (n-1) degrÃ©s de libertÃ©
```

#### IC pour une Proportion
```
IC = pÌ‚ Â± Z Ã— âˆš[pÌ‚(1-pÌ‚)/n]

OÃ¹ pÌ‚ = proportion observÃ©e (x/n)
```

### 3.3 Exemple Bancaire Complet

#### Contexte
DPO veut estimer le solde moyen des comptes Ã©pargne

**DonnÃ©es Ã©chantillon (n=100)**:
- Moyenne: 25,000 HTG
- Ã‰cart-type: 8,000 HTG

#### Calcul IC 95%
```
IC = 25,000 Â± 1.96 Ã— (8,000 / âˆš100)
IC = 25,000 Â± 1.96 Ã— 800
IC = 25,000 Â± 1,568
IC = [23,432 HTG ; 26,568 HTG]
```

#### InterprÃ©tation
"Nous sommes confiants Ã  95% que le solde moyen de TOUS les comptes Ã©pargne se situe entre 23,432 HTG et 26,568 HTG"

---

## 4. TESTS D'HYPOTHÃˆSES - VUE D'ENSEMBLE

### 4.1 Principe GÃ©nÃ©ral

#### Les 2 HypothÃ¨ses
```
Hâ‚€ (HypothÃ¨se Nulle): Pas d'effet, pas de diffÃ©rence
Hâ‚ (HypothÃ¨se Alternative): Il y a un effet ou une diffÃ©rence
```

#### Exemple Banking
```
Hâ‚€: Le taux de dÃ©faut = 5% (pas de changement)
Hâ‚: Le taux de dÃ©faut â‰  5% (il y a changement)
```

### 4.2 Les 6 Ã‰tapes OBLIGATOIRES

```
1. FORMULER Hâ‚€ et Hâ‚ clairement
2. CHOISIR Î± (risque Type I) = 0.05 gÃ©nÃ©ralement
3. SÃ‰LECTIONNER le test appropriÃ©
4. CALCULER la statistique de test
5. TROUVER la p-value
6. DÃ‰CIDER: Si p < Î± â†’ Rejeter Hâ‚€, sinon Garder Hâ‚€
```

### 4.3 Types de Tests

| Test | Hâ‚ | Quand utiliser | Exemple |
|------|-----|----------------|---------|
| **BilatÃ©ral** | Î¼ â‰  Î¼â‚€ | DiffÃ©rence dans N'IMPORTE QUELLE direction | "Le taux a-t-il CHANGÃ‰?" |
| **UnilatÃ©ral >** | Î¼ > Î¼â‚€ | Augmentation attendue | "Le taux a-t-il AUGMENTÃ‰?" |
| **UnilatÃ©ral <** | Î¼ < Î¼â‚€ | Diminution attendue | "Le taux a-t-il DIMINUÃ‰?" |

### 4.4 Les 2 Types d'Erreurs

| DÃ©cision | Hâ‚€ Vraie | Hâ‚€ Fausse |
|----------|----------|-----------|
| **Rejeter Hâ‚€** | âŒ **Erreur Type I** (Î±) | âœ… Correct |
| **Garder Hâ‚€** | âœ… Correct | âŒ **Erreur Type II** (Î²) |

#### ExpliquÃ© simplement
- **Erreur Type I** (Î± = 5%): Faux positif - On crie au loup alors qu'il n'y en a pas
- **Erreur Type II** (Î²): Faux nÃ©gatif - On ne voit pas le loup alors qu'il est lÃ 
- **Puissance** (1-Î²): ProbabilitÃ© de dÃ©tecter le loup quand il est lÃ 

#### Contexte Banking
```
Erreur Type I: DÃ©clarer qu'un client est Ã  risque alors qu'il est sain
Erreur Type II: Ne pas dÃ©tecter un client rÃ©ellement Ã  risque
```

### 4.5 La p-value ExpliquÃ©e

#### DÃ©finition
> **p-value**: ProbabilitÃ© d'observer un rÃ©sultat AUSSI EXTRÃŠME que celui obtenu, SI Hâ‚€ est vraie.

#### RÃ¨gle de DÃ©cision
```
p-value â‰¤ Î± (0.05) â†’ Rejeter Hâ‚€ (RÃ©sultat SIGNIFICATIF)
p-value > Î± â†’ Garder Hâ‚€ (Pas assez de preuves)
```

#### InterprÃ©tation par Valeur
```
p > 0.10: Aucune preuve contre Hâ‚€
0.05 < p â‰¤ 0.10: Preuve faible
0.01 < p â‰¤ 0.05: Preuve modÃ©rÃ©e
p â‰¤ 0.01: Preuve forte contre Hâ‚€
```

#### âš ï¸ ATTENTION: PiÃ¨ges de la p-value
1. p faible â‰  Effet important (peut Ãªtre significatif mais nÃ©gligeable)
2. p Ã©levÃ© â‰  Hâ‚€ est vraie (juste pas assez de preuves)
3. SignificativitÃ© statistique â‰  SignificativitÃ© pratique

---

## 5. TEST t DE STUDENT

### 5.1 Test t pour UN Ã‰chantillon

#### DÃ©finition
Compare la moyenne d'UN Ã©chantillon Ã  une valeur de rÃ©fÃ©rence

#### Quand l'utiliser
- Comparer moyenne Ã©chantillon vs valeur fixe
- DonnÃ©es continues
- Distribution normale OU n â‰¥ 30
- Ã‰cart-type population INCONNU

#### HypothÃ¨ses
```
Hâ‚€: Î¼ = Î¼â‚€
Hâ‚: Î¼ â‰  Î¼â‚€  (ou > ou <)
```

#### Formule
```
t = (xÌ„ - Î¼â‚€) / (s / âˆšn)

OÃ¹:
- xÌ„ = Moyenne Ã©chantillon
- Î¼â‚€ = Valeur de rÃ©fÃ©rence
- s = Ã‰cart-type Ã©chantillon
- n = Taille Ã©chantillon

DegrÃ©s de libertÃ©: df = n - 1
```

#### Exemple Banking Complet

**Contexte DPO**:  
Le solde moyen des comptes Premium devrait Ãªtre 50,000 HTG. On vÃ©rifie sur un Ã©chantillon.

**DonnÃ©es (n=40)**:
- Moyenne observÃ©e: 52,500 HTG
- Ã‰cart-type: 12,000 HTG

**Ã‰tape 1**: HypothÃ¨ses
```
Hâ‚€: Î¼ = 50,000 HTG
Hâ‚: Î¼ â‰  50,000 HTG (bilatÃ©ral)
Î± = 0.05
```

**Ã‰tape 2**: Calcul
```
t = (52,500 - 50,000) / (12,000 / âˆš40)
t = 2,500 / (12,000 / 6.32)
t = 2,500 / 1,898
t = 1.32
```

**Ã‰tape 3**: DÃ©cision
```
df = 40 - 1 = 39
Valeur critique t(0.025, 39) â‰ˆ 2.02
|t| = 1.32 < 2.02 â†’ Ne pas rejeter Hâ‚€
```

**Conclusion**: Le solde moyen ne diffÃ¨re PAS significativement de 50,000 HTG au seuil de 5%.

#### Conditions d'Application
âœ… Variable continue  
âœ… Ã‰chantillon alÃ©atoire  
âœ… Distribution approximativement normale (ou n â‰¥ 30)  
âœ… Observations indÃ©pendantes

---

### 5.2 Test t pour DEUX Ã‰chantillons IndÃ©pendants

#### DÃ©finition
Compare les moyennes de DEUX groupes distincts

#### Quand l'utiliser
- Comparer 2 moyennes
- Groupes indÃ©pendants (ex: Hommes vs Femmes)
- DonnÃ©es continues et normales

#### HypothÃ¨ses
```
Hâ‚€: Î¼â‚ = Î¼â‚‚  (les moyennes sont Ã©gales)
Hâ‚: Î¼â‚ â‰  Î¼â‚‚  (les moyennes diffÃ¨rent)
```

#### Formule (variances Ã©gales)
```
t = (xÌ„â‚ - xÌ„â‚‚) / âˆš[sÂ²pooled Ã— (1/nâ‚ + 1/nâ‚‚)]

sÂ²pooled = [(nâ‚-1)sâ‚Â² + (nâ‚‚-1)sâ‚‚Â²] / (nâ‚ + nâ‚‚ - 2)

df = nâ‚ + nâ‚‚ - 2
```

#### Exemple Banking

**Contexte**: Comparer soldes moyens Premium vs Standard

**DonnÃ©es**:
- Premium (nâ‚=50): xÌ„â‚ = 45,000 HTG, sâ‚ = 10,000 HTG
- Standard (nâ‚‚=50): xÌ„â‚‚ = 15,000 HTG, sâ‚‚ = 8,000 HTG

**Ã‰tape 1**: HypothÃ¨ses
```
Hâ‚€: Î¼_Premium = Î¼_Standard
Hâ‚: Î¼_Premium â‰  Î¼_Standard
Î± = 0.05
```

**Ã‰tape 2**: Variance poolÃ©e
```
sÂ²pooled = [(49Ã—10,000Â²) + (49Ã—8,000Â²)] / 98
sÂ²pooled = [4.9B + 3.1B] / 98
sÂ²pooled = 81,632,653
s_pooled = 9,035 HTG
```

**Ã‰tape 3**: Calcul t
```
t = (45,000 - 15,000) / âˆš[81,632,653 Ã— (1/50 + 1/50)]
t = 30,000 / (9,035 Ã— 0.2)
t = 30,000 / 1,807
t = 16.60
```

**Ã‰tape 4**: DÃ©cision
```
df = 98
Valeur critique â‰ˆ 1.98
|t| = 16.60 >> 1.98 â†’ Rejeter Hâ‚€ fortement!
```

**Conclusion**: Les soldes moyens diffÃ¨rent SIGNIFICATIVEMENT entre Premium et Standard (p < 0.001).

#### Test de Welch (variances inÃ©gales)
Si test de Levene montre variances diffÃ©rentes â†’ Utiliser formule de Welch (pas poolÃ©e)

---

### 5.3 Test t pour Ã‰chantillons APPARIÃ‰S

#### DÃ©finition
Compare DEUX mesures sur les MÃŠMES individus (avant/aprÃ¨s)

#### Quand l'utiliser
- Mesures avant/aprÃ¨s
- Mesures rÃ©pÃ©tÃ©es
- Paires appariÃ©es (jumeaux, etc.)

#### Principe
On calcule les DIFFÃ‰RENCES pour chaque sujet, puis test t sur ces diffÃ©rences.

#### HypothÃ¨ses
```
Hâ‚€: Î¼_diff = 0  (pas de changement)
Hâ‚: Î¼_diff â‰  0  (il y a changement)
```

#### Formule
```
t = dÌ„ / (s_d / âˆšn)

OÃ¹:
- dÌ„ = Moyenne des diffÃ©rences
- s_d = Ã‰cart-type des diffÃ©rences
- n = Nombre de paires
```

#### Exemple Banking

**Contexte**: Formation agents - Ventes avant vs aprÃ¨s

**DonnÃ©es (n=25 agents)**:
- Moyenne diffÃ©rence (aprÃ¨s - avant): +5 ventes
- Ã‰cart-type des diffÃ©rences: 8 ventes

**Ã‰tape 1**: HypothÃ¨ses
```
Hâ‚€: La formation n'a pas d'effet (Î¼_diff = 0)
Hâ‚: La formation a un effet (Î¼_diff â‰  0)
Î± = 0.05
```

**Ã‰tape 2**: Calcul
```
t = 5 / (8 / âˆš25)
t = 5 / (8 / 5)
t = 5 / 1.6
t = 3.13
```

**Ã‰tape 3**: DÃ©cision
```
df = 25 - 1 = 24
Valeur critique t(0.025, 24) â‰ˆ 2.06
|t| = 3.13 > 2.06 â†’ Rejeter Hâ‚€
```

**Conclusion**: La formation a SIGNIFICATIVEMENT augmentÃ© les ventes (p < 0.05).

---

## 6. TEST Z POUR PROPORTIONS

### 6.1 Test Z pour UNE Proportion

#### DÃ©finition
Compare une proportion observÃ©e Ã  une valeur de rÃ©fÃ©rence

#### Quand l'utiliser
- Variable binaire (SuccÃ¨s/Ã‰chec)
- Grand Ã©chantillon (np â‰¥ 5 ET n(1-p) â‰¥ 5)
- Comparer taux observÃ© vs taux thÃ©orique

#### HypothÃ¨ses
```
Hâ‚€: p = pâ‚€
Hâ‚: p â‰  pâ‚€  (ou > ou <)
```

#### Formule
```
Z = (pÌ‚ - pâ‚€) / âˆš[pâ‚€(1-pâ‚€)/n]

OÃ¹:
- pÌ‚ = Proportion observÃ©e (x/n)
- pâ‚€ = Proportion de rÃ©fÃ©rence
- n = Taille Ã©chantillon
```

#### Exemple Banking

**Contexte**: Le taux de dÃ©faut devrait Ãªtre 5%. On vÃ©rifie.

**DonnÃ©es**:
- Ã‰chantillon: n = 1000 prÃªts
- DÃ©fauts observÃ©s: 60
- pÌ‚ = 60/1000 = 0.06 (6%)

**Ã‰tape 1**: HypothÃ¨ses
```
Hâ‚€: p = 0.05 (taux normal)
Hâ‚: p > 0.05 (taux anormalement Ã©levÃ©)
Î± = 0.05 (unilatÃ©ral)
```

**Ã‰tape 2**: VÃ©rification conditions
```
npâ‚€ = 1000 Ã— 0.05 = 50 â‰¥ 5 âœ“
n(1-pâ‚€) = 1000 Ã— 0.95 = 950 â‰¥ 5 âœ“
```

**Ã‰tape 3**: Calcul
```
Z = (0.06 - 0.05) / âˆš[0.05Ã—0.95/1000]
Z = 0.01 / âˆš(0.0000475)
Z = 0.01 / 0.00689
Z = 1.45
```

**Ã‰tape 4**: DÃ©cision
```
Valeur critique Z(0.05) = 1.645
Z = 1.45 < 1.645 â†’ Ne pas rejeter Hâ‚€
```

**Conclusion**: Le taux de dÃ©faut ne diffÃ¨re PAS significativement de 5%.

---

### 6.2 Test Z pour DEUX Proportions

#### DÃ©finition
Compare les proportions de DEUX groupes indÃ©pendants

#### Quand l'utiliser
- Comparer taux entre 2 groupes
- Variables binaires
- Grands Ã©chantillons

#### HypothÃ¨ses
```
Hâ‚€: pâ‚ = pâ‚‚
Hâ‚: pâ‚ â‰  pâ‚‚
```

#### Formule
```
Z = (pÌ‚â‚ - pÌ‚â‚‚) / âˆš[pÌ‚(1-pÌ‚) Ã— (1/nâ‚ + 1/nâ‚‚)]

OÃ¹ pÌ‚ = (xâ‚ + xâ‚‚) / (nâ‚ + nâ‚‚)  (proportion poolÃ©e)
```

#### Exemple Banking

**Contexte**: Comparer taux de conversion entre 2 campagnes

**DonnÃ©es**:
- Campagne A: 120 conversions sur 1000 clients (12%)
- Campagne B: 150 conversions sur 1000 clients (15%)

**Ã‰tape 1**: HypothÃ¨ses
```
Hâ‚€: p_A = p_B
Hâ‚: p_A â‰  p_B
Î± = 0.05
```

**Ã‰tape 2**: Proportion poolÃ©e
```
pÌ‚ = (120 + 150) / (1000 + 1000) = 270/2000 = 0.135
```

**Ã‰tape 3**: Calcul
```
Z = (0.12 - 0.15) / âˆš[0.135Ã—0.865 Ã— (1/1000 + 1/1000)]
Z = -0.03 / âˆš[0.1168 Ã— 0.002]
Z = -0.03 / 0.0153
Z = -1.96
```

**Ã‰tape 4**: DÃ©cision
```
Valeur critique = Â±1.96
|Z| = 1.96 â†’ Juste Ã  la limite! p â‰ˆ 0.05
```

**Conclusion**: La diffÃ©rence est JUSTE significative au seuil de 5%. Campagne B performe mieux.

---

## 7. TEST DU CHI-CARRÃ‰ (Ï‡Â²)

### 7.1 Test d'IndÃ©pendance

#### DÃ©finition
Teste si DEUX variables catÃ©gorielles sont indÃ©pendantes

#### Quand l'utiliser
- 2 variables catÃ©gorielles
- Tableau de contingence
- Effectifs attendus â‰¥ 5 dans chaque cellule

#### HypothÃ¨ses
```
Hâ‚€: Les variables sont indÃ©pendantes
Hâ‚: Les variables sont dÃ©pendantes (liÃ©es)
```

#### Formule
```
Ï‡Â² = Î£ [(O - E)Â² / E]

OÃ¹:
- O = FrÃ©quence ObservÃ©e
- E = FrÃ©quence Attendue = (Total ligne Ã— Total colonne) / Total gÃ©nÃ©ral

df = (nombre lignes - 1) Ã— (nombre colonnes - 1)
```

#### Exemple Banking

**Contexte**: Le canal prÃ©fÃ©rÃ© dÃ©pend-il du segment client?

**Tableau ObservÃ©**:
|          | Agence | Mobile | Web | Total |
|----------|--------|--------|-----|-------|
| Premium  | 60     | 30     | 10  | 100   |
| Standard | 40     | 50     | 110 | 200   |
| **Total**| 100    | 80     | 120 | 300   |

**Ã‰tape 1**: HypothÃ¨ses
```
Hâ‚€: Canal indÃ©pendant du segment
Hâ‚: Canal dÃ©pend du segment
Î± = 0.05
```

**Ã‰tape 2**: Calcul des Attendus
```
E(Premium, Agence) = (100 Ã— 100) / 300 = 33.33
E(Premium, Mobile) = (100 Ã— 80) / 300 = 26.67
E(Premium, Web) = (100 Ã— 120) / 300 = 40.00
... (faire pour chaque cellule)
```

**Ã‰tape 3**: Calcul Ï‡Â²
```
Ï‡Â² = (60-33.33)Â²/33.33 + (30-26.67)Â²/26.67 + (10-40)Â²/40 + ...
Ï‡Â² = 21.33 + 0.42 + 22.50 + ...
Ï‡Â² â‰ˆ 65.25
```

**Ã‰tape 4**: DÃ©cision
```
df = (2-1) Ã— (3-1) = 2
Valeur critique Ï‡Â²(0.05, 2) = 5.99
Ï‡Â² = 65.25 >> 5.99 â†’ Rejeter Hâ‚€ FORTEMENT
```

**Conclusion**: Le canal prÃ©fÃ©rÃ© DÃ‰PEND SIGNIFICATIVEMENT du segment (p < 0.001).

#### InterprÃ©tation Business
Les clients Premium prÃ©fÃ¨rent l'agence, les Standard prÃ©fÃ¨rent le Web.

---

### 7.2 Test d'Ajustement (Goodness of Fit)

#### DÃ©finition
Teste si les donnÃ©es suivent une distribution thÃ©orique

#### Quand l'utiliser
- VÃ©rifier uniformitÃ©
- Comparer distribution observÃ©e vs attendue
- Une seule variable catÃ©gorielle

#### HypothÃ¨ses
```
Hâ‚€: Les donnÃ©es suivent la distribution thÃ©orique
Hâ‚: Les donnÃ©es ne suivent pas la distribution
```

#### Exemple Banking

**Contexte**: Les transactions sont-elles uniformes par jour de semaine?

**DonnÃ©es**:
| Jour | ObservÃ© | Attendu (uniforme) |
|------|---------|-------------------|
| Lun  | 180     | 700/7 = 100       |
| Mar  | 120     | 100               |
| Mer  | 90      | 100               |
| Jeu  | 85      | 100               |
| Ven  | 150     | 100               |
| Sam  | 50      | 100               |
| Dim  | 25      | 100               |

**Ã‰tape 1**: Calcul Ï‡Â²
```
Ï‡Â² = (180-100)Â²/100 + (120-100)Â²/100 + ... + (25-100)Â²/100
Ï‡Â² = 64 + 4 + 1 + 2.25 + 25 + 25 + 56.25
Ï‡Â² = 177.5
```

**Ã‰tape 2**: DÃ©cision
```
df = 7 - 1 = 6
Valeur critique Ï‡Â²(0.05, 6) = 12.59
Ï‡Â² = 177.5 >> 12.59 â†’ Rejeter Hâ‚€
```

**Conclusion**: Les transactions NE SONT PAS uniformes. Il y a clairement plus d'activitÃ© en dÃ©but de semaine.

---

## 8. ANOVA (Analysis of Variance)

### 8.1 ANOVA Ã  UN Facteur

#### DÃ©finition
Compare les moyennes de 3 GROUPES OU PLUS

#### Quand l'utiliser
- Comparer 3+ moyennes
- Variable continue
- Groupes indÃ©pendants
- Distribution normale dans chaque groupe
- Variances homogÃ¨nes

#### HypothÃ¨ses
```
Hâ‚€: Î¼â‚ = Î¼â‚‚ = Î¼â‚ƒ = ... = Î¼â‚–  (toutes les moyennes Ã©gales)
Hâ‚: Au moins UNE moyenne diffÃ¨re
```

#### Principe
ANOVA compare la variation ENTRE groupes vs variation Ã€ L'INTÃ‰RIEUR des groupes.

```
F = Variance ENTRE / Variance INTRA

Si F grand â†’ Les groupes diffÃ¨rent significativement
```

#### Formule
```
F = MSB / MSW

OÃ¹:
MSB = SSB / (k-1)  (Moyenne des carrÃ©s ENTRE)
MSW = SSW / (N-k)  (Moyenne des carrÃ©s Ã€ L'INTÃ‰RIEUR)

df1 = k - 1  (nombre groupes - 1)
df2 = N - k  (total - nombre groupes)
```

#### Exemple Banking

**Contexte**: Les soldes moyens diffÃ¨rent-ils entre les 4 agences?

**DonnÃ©es**:
- Agence Nord (n=30): xÌ„ = 20,000 HTG
- Agence Sud (n=30): xÌ„ = 25,000 HTG
- Agence Est (n=30): xÌ„ = 22,000 HTG
- Agence Ouest (n=30): xÌ„ = 28,000 HTG

**Ã‰tape 1**: HypothÃ¨ses
```
Hâ‚€: Les 4 agences ont le mÃªme solde moyen
Hâ‚: Au moins une agence diffÃ¨re
Î± = 0.05
```

**Ã‰tape 2**: Calcul ANOVA
(Calculs simplifiÃ©s)
```
Supposons F = 12.45
df1 = 4 - 1 = 3
df2 = 120 - 4 = 116
```

**Ã‰tape 3**: DÃ©cision
```
Valeur critique F(0.05, 3, 116) â‰ˆ 2.68
F = 12.45 > 2.68 â†’ Rejeter Hâ‚€
```

**Conclusion**: Les soldes moyens diffÃ¨rent SIGNIFICATIVEMENT entre agences.

---

### 8.2 Tests Post-Hoc (AprÃ¨s ANOVA)

#### ProblÃ¨me
ANOVA dit "au moins une diffÃ©rence" mais ne dit PAS laquelle!

#### Solution: Tests Post-Hoc

| Test | Usage | Avantage |
|------|-------|----------|
| **Tukey HSD** | Toutes comparaisons | ContrÃ´le erreur familiale |
| **Bonferroni** | Peu de comparaisons | TrÃ¨s conservateur |
| **ScheffÃ©** | Comparaisons complexes | Flexible |

#### ProcÃ©dure Tukey HSD

**Formule**:
```
HSD = q Ã— âˆš(MSW / n)

OÃ¹ q = valeur de Tukey (table)
```

**Exemple**: Comparer Agence Nord vs Sud
```
DiffÃ©rence = |20,000 - 25,000| = 5,000 HTG
HSD = 3.70 Ã— âˆš(25,000,000 / 30) = 3,377 HTG

5,000 > 3,377 â†’ DiffÃ©rence significative!
```

---

## 9. TESTS NON-PARAMÃ‰TRIQUES

### 9.1 Quand Utiliser les Tests Non-ParamÃ©triques?

#### Situations
1. **Distribution non normale** (asymÃ©trique, bimodale)
2. **Petit Ã©chantillon** (n < 30)
3. **DonnÃ©es ordinales** (ranking, Ã©chelles)
4. **Outliers importants**
5. **Variances trÃ¨s inÃ©gales**

#### Avantages
- Moins d'hypothÃ¨ses
- Robustes aux outliers
- Applicables aux donnÃ©es ordinales

#### InconvÃ©nients
- Moins de puissance statistique
- Moins sensibles aux petits effets

---

### 9.2 Correspondance Tests ParamÃ©triques â†” Non-ParamÃ©triques

| ParamÃ©trique | Non-ParamÃ©trique | Usage |
|--------------|------------------|-------|
| Test t (1 Ã©chantillon) | **Wilcoxon signÃ©-rang** | 1 mÃ©diane vs valeur |
| Test t (2 Ã©chantillons indÃ©p.) | **Mann-Whitney U** | Comparer 2 mÃ©dianes |
| Test t (appariÃ©s) | **Wilcoxon signÃ©-rang** | Avant/aprÃ¨s |
| ANOVA | **Kruskal-Wallis** | Comparer 3+ mÃ©dianes |
| CorrÃ©lation Pearson | **Spearman** | CorrÃ©lation ordinale |

---

### 9.3 Test de Mann-Whitney U

#### DÃ©finition
Teste si DEUX groupes indÃ©pendants ont la mÃªme distribution

#### HypothÃ¨ses
```
Hâ‚€: Les distributions sont identiques
Hâ‚: Une distribution est dÃ©calÃ©e par rapport Ã  l'autre
```

#### Principe
1. Combiner les donnÃ©es des 2 groupes
2. Attribuer des rangs
3. Comparer sommes des rangs

#### Exemple Banking

**Contexte**: Satisfaction clients Premium vs Standard

**DonnÃ©es** (Ã©chelle 1-5):
- Premium: 5, 4, 5, 4, 3
- Standard: 3, 2, 3, 2, 1

**Ã‰tape 1**: Ranger TOUTES les valeurs
```
1(S), 2(S), 2(S), 3(P), 3(S), 3(S), 4(P), 4(P), 5(P), 5(P)
Rangs: 1, 2.5, 2.5, 5, 5, 5, 7.5, 7.5, 9.5, 9.5
```

**Ã‰tape 2**: Somme des rangs
```
Premium: 5 + 7.5 + 7.5 + 9.5 + 9.5 = 39
Standard: 1 + 2.5 + 2.5 + 5 + 5 = 16
```

**Ã‰tape 3**: Calcul U
```
Uâ‚ = nâ‚nâ‚‚ + nâ‚(nâ‚+1)/2 - Râ‚
Uâ‚ = 5Ã—5 + 5Ã—6/2 - 39 = 25 + 15 - 39 = 1

Uâ‚‚ = nâ‚nâ‚‚ - Uâ‚ = 25 - 1 = 24
U = min(Uâ‚, Uâ‚‚) = 1
```

**Ã‰tape 4**: DÃ©cision
```
Valeur critique U(0.05, 5, 5) = 2
U = 1 < 2 â†’ Rejeter Hâ‚€
```

**Conclusion**: Premium a une satisfaction SIGNIFICATIVEMENT supÃ©rieure.

---

### 9.4 Test de Kruskal-Wallis

#### DÃ©finition
Version non-paramÃ©trique de l'ANOVA (3+ groupes)

#### Quand l'utiliser
- Comparer 3+ groupes
- Distribution non normale
- DonnÃ©es ordinales

#### HypothÃ¨ses
```
Hâ‚€: Toutes les distributions sont identiques
Hâ‚: Au moins une distribution diffÃ¨re
```

#### Formule
```
H = [12 / N(N+1)] Ã— Î£[RÂ²áµ¢/náµ¢] - 3(N+1)

OÃ¹:
- N = Total observations
- Ráµ¢ = Somme des rangs groupe i
- náµ¢ = Taille groupe i

Suit approximativement Ï‡Â² avec df = k-1
```

#### Exemple Banking

**Contexte**: Comparer scores satisfaction 3 agences

**DonnÃ©es rangÃ©es**:
- Agence A: Somme rangs = 150, n = 10
- Agence B: Somme rangs = 200, n = 10
- Agence C: Somme rangs = 115, n = 10

**Calcul**:
```
H = [12 / 30Ã—31] Ã— [(150Â²/10) + (200Â²/10) + (115Â²/10)] - 3Ã—31
H â‰ˆ 6.45
```

**DÃ©cision**:
```
Ï‡Â²(0.05, 2) = 5.99
H = 6.45 > 5.99 â†’ Rejeter Hâ‚€
```

**Conclusion**: Les distributions de satisfaction diffÃ¨rent entre agences.

---

### 9.5 CorrÃ©lation de Spearman

#### DÃ©finition
Mesure la force d'une relation MONOTONE entre 2 variables

#### DiffÃ©rence avec Pearson
- **Pearson (r)**: Relation LINÃ‰AIRE, donnÃ©es normales
- **Spearman (Ï)**: Relation MONOTONE, basÃ©e sur RANGS

#### Quand utiliser
- DonnÃ©es ordinales
- Relation non linÃ©aire mais monotone
- PrÃ©sence d'outliers
- Distribution non normale

#### Formule
```
Ï = 1 - [6Î£dÂ²áµ¢ / n(nÂ²-1)]

OÃ¹ dáµ¢ = diffÃ©rence de rangs pour chaque observation
```

#### InterprÃ©tation (identique Ã  Pearson)
```
|Ï| < 0.3: CorrÃ©lation faible
0.3 â‰¤ |Ï| â‰¤ 0.7: CorrÃ©lation modÃ©rÃ©e
|Ï| > 0.7: CorrÃ©lation forte
```

#### Exemple Banking

**Contexte**: Relation entre score crÃ©dit et montant prÃªt accordÃ©

**DonnÃ©es**:
| Client | Score | Montant | Rang Score | Rang Montant | d | dÂ² |
|--------|-------|---------|------------|--------------|---|-----|
| 1      | 750   | 50K     | 5          | 5            | 0 | 0   |
| 2      | 650   | 30K     | 3          | 3            | 0 | 0   |
| 3      | 800   | 60K     | 6          | 6            | 0 | 0   |
| 4      | 600   | 20K     | 2          | 2            | 0 | 0   |
| 5      | 550   | 15K     | 1          | 1            | 0 | 0   |
| 6      | 700   | 40K     | 4          | 4            | 0 | 0   |

**Calcul**:
```
Î£dÂ² = 0
Ï = 1 - [6Ã—0 / 6(36-1)] = 1 - 0 = 1.0
```

**Conclusion**: CorrÃ©lation PARFAITE positive â†’ Plus le score est Ã©levÃ©, plus le montant accordÃ© est important.

---

## 10. ARBRES DE DÃ‰CISION

### 10.1 Arbre Global: Quel Test Choisir?

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ QUELLE EST VOTRE QUESTION?      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚                   â”‚
COMPARER            TESTER
GROUPES             ASSOCIATION
    â”‚                   â”‚
    â–¼                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Combien â”‚      â”‚ 2 Variables  â”‚
â”‚ groupes?â”‚      â”‚ CatÃ©goriellesâ”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚                   â”‚
    â”œâ”€ 1 groupe â”€â”€â”€â”€â”€â”€â–º Test t (1 Ã©chantillon)
    â”‚                   ou Wilcoxon
    â”‚
    â”œâ”€ 2 groupes â”€â”€â”€â”€â”€â”
    â”‚                 â”‚
    â”‚            â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”
    â”‚            â”‚ Type?   â”‚
    â”‚            â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
    â”‚                 â”‚
    â”‚         â”Œâ”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”
    â”‚         â”‚               â”‚
    â”‚    IndÃ©pendants    AppariÃ©s
    â”‚         â”‚               â”‚
    â”‚     t-test ind.     t-test app.
    â”‚     Mann-Whitney    Wilcoxon
    â”‚
    â””â”€ 3+ groupes â”€â”€â”€â”€â–º ANOVA
                        Kruskal-Wallis

ASSOCIATION
    â”‚
    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Type variables?â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚
    â”œâ”€ 2 CatÃ©gorielles â”€â”€â–º Chi-carrÃ©
    â”‚
    â”œâ”€ 2 Continues â”€â”€â”€â”€â”€â”€â–º Pearson / Spearman
    â”‚
    â””â”€ Continues + CatÃ©gorielle â”€â”€â–º RÃ©gression / ANOVA
```

---

### 10.2 Arbre: Test ParamÃ©trique ou Non-ParamÃ©trique?

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ DonnÃ©es Normales?       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
    â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”
    â”‚         â”‚
   OUI       NON â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º Tests NON-PARAMÃ‰TRIQUES
    â”‚                       (Mann-Whitney, Wilcoxon,
    â”‚                        Kruskal-Wallis, Spearman)
    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ n â‰¥ 30?         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚
    â”œâ”€ OUI â”€â”€â–º Tests PARAMÃ‰TRIQUES
    â”‚           (t-test, ANOVA, Pearson)
    â”‚
    â””â”€ NON â”€â”€â”
             â”‚
      â”Œâ”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”
      â”‚ Outliers    â”‚
      â”‚ importants? â”‚
      â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
             â”‚
        â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”
        â”‚         â”‚
       OUI       NON
        â”‚         â”‚
   NON-PARAM.  PARAMÃ‰TRIQUE
              (avec prÃ©caution)
```

---

### 10.3 Arbre: Comparer 2 Moyennes

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Comparer 2 MOYENNES        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚                   â”‚
IndÃ©pendants       AppariÃ©s
    â”‚                   â”‚
    â–¼                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Normal? â”‚      â”‚ Normal?  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚                   â”‚
â”Œâ”€â”€â”€â”´â”€â”€â”€â”           â”Œâ”€â”€â”€â”´â”€â”€â”€â”
â”‚       â”‚           â”‚       â”‚
OUI    NON         OUI    NON
â”‚       â”‚           â”‚       â”‚
â–¼       â–¼           â–¼       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚Variances â”‚  â”‚Mann-     â”‚  â”‚t-test    â”‚  â”‚Wilcoxon  â”‚
â”‚Ã©gales?   â”‚  â”‚Whitney U â”‚  â”‚appariÃ©   â”‚  â”‚signed    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚
â”Œâ”€â”€â”€â”´â”€â”€â”€â”
â”‚       â”‚
OUI    NON
â”‚       â”‚
â–¼       â–¼
t-test  Welch
indÃ©p.  t-test
```

---

### 10.4 Arbre: Comparer 3+ Groupes

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Comparer 3+ GROUPES         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚                   â”‚
Distribution         Distribution
Normale              NON Normale
    â”‚                   â”‚
    â–¼                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚Variances â”‚      â”‚ Kruskal-     â”‚
â”‚Ã©gales?   â”‚      â”‚ Wallis       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚                   â”‚
â”Œâ”€â”€â”€â”´â”€â”€â”€â”          p < Î±?
â”‚       â”‚               â”‚
OUI    NON              â–¼
â”‚       â”‚         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â–¼       â–¼         â”‚ Tests    â”‚
ANOVA   Welch     â”‚ Post-hoc â”‚
        ANOVA     â”‚ (Dunn)   â”‚
    â”‚             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
p < Î±?
    â”‚
    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Tests    â”‚
â”‚ Post-hoc â”‚
â”‚ (Tukey)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

### 10.5 Arbre: Tests de Proportions

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Tester PROPORTIONS         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚                   â”‚
1 Proportion      2+ Proportions
    â”‚                   â”‚
    â–¼                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚np â‰¥ 5 ET â”‚      â”‚ Groupes      â”‚
â”‚n(1-p)â‰¥5? â”‚      â”‚ indÃ©pendants?â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚                   â”‚
    â”œâ”€ OUI â”€â”€â–º Test Z   â”‚
    â”‚                   â”œâ”€ OUI â”€â”€â–º Test Z (2 prop)
    â””â”€ NON â”€â”€â–º Test     â”‚          ou Chi-carrÃ©
              Exact     â”‚
              Binomial  â””â”€ NON â”€â”€â–º McNemar
                                  (appariÃ©s)
```

---

### 10.6 Arbre: Tests d'Association

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Tester ASSOCIATION         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚                   â”‚
2 CatÃ©gorielles    2 Continues
    â”‚                   â”‚
    â–¼                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚Effectifs â”‚      â”‚ Normal?  â”‚
â”‚attendus  â”‚      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚â‰¥ 5?      â”‚            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”Œâ”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”
    â”‚             â”‚           â”‚
â”Œâ”€â”€â”€â”´â”€â”€â”€â”        OUI         NON
â”‚       â”‚         â”‚           â”‚
OUI    NON        â–¼           â–¼
â”‚       â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â–¼       â–¼    â”‚LinÃ©aire? â”‚  â”‚Spearman  â”‚
ChiÂ²    Fisherâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚(monotone)â”‚
exact         â”‚           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”
         â”‚         â”‚
        OUI       NON
         â”‚         â”‚
         â–¼         â–¼
    Pearson    Spearman
    (linÃ©aire)
```

---

## 11. SCÃ‰NARIOS BANCAIRES TYPES

### ScÃ©nario 1: Audit ConformitÃ© RGPD

**Contexte**:  
Le DPO doit vÃ©rifier si le taux de non-conformitÃ© est acceptable (<5%)

**Question**: Sur 500 dossiers auditÃ©s, 35 sont non-conformes (7%). Est-ce significativement supÃ©rieur Ã  5%?

**Test Ã  utiliser**: Test Z pour une proportion (unilatÃ©ral droit)

**HypothÃ¨ses**:
```
Hâ‚€: p â‰¤ 0.05 (taux acceptable)
Hâ‚: p > 0.05 (taux inacceptable)
Î± = 0.05
```

**Calcul**:
```
pÌ‚ = 35/500 = 0.07
Z = (0.07 - 0.05) / âˆš[0.05Ã—0.95/500]
Z = 0.02 / 0.00975
Z = 2.05

Valeur critique Z(0.05) = 1.645
Z = 2.05 > 1.645 â†’ Rejeter Hâ‚€
```

**DÃ©cision**: Le taux de non-conformitÃ© est SIGNIFICATIVEMENT supÃ©rieur Ã  5% (p = 0.02). Action corrective nÃ©cessaire!

**Graphique Mental**:
```
    Taux acceptable     Zone critique
    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º
         5%          7%
              â†‘
         Taux observÃ©
         (ALERTE!)
```

---

### ScÃ©nario 2: Comparaison Performance Agences

**Contexte**:  
Comparer le solde moyen des comptes entre 3 agences

**DonnÃ©es**:
- Nord (n=50): xÌ„ = 25,000 HTG, s = 10,000
- Sud (n=50): xÌ„ = 30,000 HTG, s = 12,000
- Est (n=50): xÌ„ = 28,000 HTG, s = 11,000

**Question**: Les soldes moyens diffÃ¨rent-ils?

**Test Ã  utiliser**: ANOVA Ã  un facteur

**HypothÃ¨ses**:
```
Hâ‚€: Î¼_Nord = Î¼_Sud = Î¼_Est
Hâ‚: Au moins une moyenne diffÃ¨re
Î± = 0.05
```

**RÃ©sultat (simplifiÃ©)**:
```
F = 8.45, p = 0.0003
```

**DÃ©cision**: Les agences diffÃ¨rent significativement (p < 0.001)

**Post-hoc Tukey**:
```
Nord vs Sud: DiffÃ©rence significative (p = 0.001)
Nord vs Est: Pas de diffÃ©rence (p = 0.12)
Sud vs Est: Pas de diffÃ©rence (p = 0.35)
```

**Conclusion Business**: L'agence Sud a des soldes significativement plus Ã©levÃ©s que le Nord. Analyser pourquoi (clientÃ¨le plus aisÃ©e? meilleurs agents?).

---

### ScÃ©nario 3: A/B Test Campagne Email

**Contexte**:  
Tester 2 versions d'email pour promouvoir un nouveau produit

**DonnÃ©es**:
- Version A (n=1000): 120 conversions (12%)
- Version B (n=1000): 150 conversions (15%)

**Question**: Version B est-elle significativement meilleure?

**Test Ã  utiliser**: Test Z pour deux proportions

**HypothÃ¨ses**:
```
Hâ‚€: p_A = p_B
Hâ‚: p_B > p_A (unilatÃ©ral)
Î± = 0.05
```

**Calcul**:
```
pÌ‚ = (120+150)/2000 = 0.135
Z = (0.15-0.12) / âˆš[0.135Ã—0.865Ã—(1/1000+1/1000)]
Z = 0.03 / 0.0153
Z = 1.96

Valeur critique = 1.645
Z = 1.96 > 1.645 â†’ Rejeter Hâ‚€
```

**DÃ©cision**: Version B est significativement meilleure (p = 0.025)

**Impact Business**:
```
Lift = (15% - 12%) / 12% Ã— 100% = 25%

Sur 10,000 clients:
- Version A: 1,200 conversions
- Version B: 1,500 conversions
- Gain: +300 clients (soit +25%)
```

**Recommandation**: DÃ©ployer la Version B!

---

### ScÃ©nario 4: Effet Formation Agents

**Contexte**:  
VÃ©rifier si une formation amÃ©liore les ventes des agents

**DonnÃ©es** (n=20 agents):
- Ventes AVANT formation: Moyenne = 15 produits/mois
- Ventes APRÃˆS formation: Moyenne = 18 produits/mois
- Moyenne des diffÃ©rences: +3 produits
- Ã‰cart-type des diffÃ©rences: 5 produits

**Question**: La formation a-t-elle un effet significatif?

**Test Ã  utiliser**: Test t appariÃ©

**HypothÃ¨ses**:
```
Hâ‚€: Î¼_diff = 0 (pas d'effet)
Hâ‚: Î¼_diff > 0 (amÃ©lioration)
Î± = 0.05
```

**Calcul**:
```
t = 3 / (5 / âˆš20)
t = 3 / 1.118
t = 2.68

df = 19
Valeur critique t(0.05, 19) = 1.729
t = 2.68 > 1.729 â†’ Rejeter Hâ‚€
```

**DÃ©cision**: La formation amÃ©liore significativement les ventes (p = 0.007)

**Taille d'effet**:
```
Cohen's d = 3 / 5 = 0.6 (effet MODÃ‰RÃ‰ Ã  FORT)
```

**ROI Formation**:
```
CoÃ»t formation: 500 USD/agent
Gain moyen: +3 produits Ã— 50 USD commission = +150 USD/mois
ROI = 150/500 = 30% par mois â†’ Rentable dÃ¨s le 4Ã¨me mois!
```

---

### ScÃ©nario 5: Satisfaction Client par Segment

**Contexte**:  
Comparer la satisfaction (Ã©chelle 1-5) entre segments

**DonnÃ©es**:
- Premium: 4.5, 5, 4, 5, 4.5 (MÃ©diane = 4.5)
- Standard: 3, 3.5, 3, 4, 3.5 (MÃ©diane = 3.5)

**Question**: Les satisfactions diffÃ¨rent-elles?

**Test Ã  utiliser**: Mann-Whitney U (donnÃ©es ordinales)

**HypothÃ¨ses**:
```
Hâ‚€: Les distributions sont identiques
Hâ‚: Premium > Standard
Î± = 0.05
```

**RÃ©sultat**:
```
U = 2, p = 0.016
```

**DÃ©cision**: Premium a une satisfaction significativement supÃ©rieure (p = 0.016)

**Action Business**: Analyser ce qui diffÃ©rencie l'expÃ©rience Premium pour l'amÃ©liorer chez Standard.

---

## 12. PIÃˆGES FRÃ‰QUENTS Ã€ Ã‰VITER

### PiÃ¨ge 1: Confondre CorrÃ©lation et CausalitÃ©

âŒ **Erreur**: "Il y a corrÃ©lation entre ice cream et noyades, donc l'ice cream cause les noyades!"

âœ… **Correct**: "CorrÃ©lation ne prouve PAS causalitÃ©. Variable cachÃ©e = tempÃ©rature estivale."

---

### PiÃ¨ge 2: Ignorer la Taille d'Effet

âŒ **Erreur**: "p = 0.001 donc rÃ©sultat trÃ¨s important!"

âœ… **Correct**: "p < 0.05 = significatif, MAIS effet peut Ãªtre nÃ©gligeable. Calculer Cohen's d ou diffÃ©rence pratique."

**Exemple**:
```
DiffÃ©rence significative de 10 HTG sur solde moyen de 100,000 HTG
â†’ Significatif statistiquement
â†’ NÃ©gligeable pratiquement (0.01%)
```

---

### PiÃ¨ge 3: Multiple Testing (Comparaisons Multiples)

âŒ **Erreur**: Faire 20 tests Ã  Î±=0.05 sans correction â†’ 1 faux positif attendu!

âœ… **Correct**: Appliquer correction de Bonferroni: Î±_ajustÃ© = 0.05/20 = 0.0025

---

### PiÃ¨ge 4: p-Hacking (Chercher la SignificativitÃ©)

âŒ **Erreur**: Tester plein de variables jusqu'Ã  trouver p < 0.05

âœ… **Correct**: DÃ©finir hypothÃ¨ses AVANT de voir les donnÃ©es

---

### PiÃ¨ge 5: Ã‰chantillon Non ReprÃ©sentatif

âŒ **Erreur**: EnquÃªte satisfaction en interrogeant seulement clients en agence

âœ… **Correct**: Ã‰chantillonnage alÃ©atoire de TOUS les clients (agence + digital)

---

### PiÃ¨ge 6: InterprÃ©tation Incorrecte IC

âŒ **Erreur**: "Il y a 95% de chances que Î¼ soit dans [23K, 27K]"

âœ… **Correct**: "On est confiant Ã  95% que Î¼ est dans [23K, 27K]"

---

### PiÃ¨ge 7: Utiliser Test ParamÃ©trique sans VÃ©rifier Conditions

âŒ **Erreur**: t-test sur donnÃ©es trÃ¨s asymÃ©triques avec n=15

âœ… **Correct**: VÃ©rifier normalitÃ© (Shapiro-Wilk) OU utiliser Mann-Whitney

---

### PiÃ¨ge 8: Confondre Moyenne et MÃ©diane

âŒ **Erreur**: "Solde moyen = 50K donc clients typiques ont 50K"

âœ… **Correct**: Si distribution asymÃ©trique â†’ MÃ©diane plus reprÃ©sentative

**Exemple**:
```
Soldes: 5K, 6K, 7K, 8K, 500K
Moyenne = 105K (faussÃ©e par outlier)
MÃ©diane = 7K (reprÃ©sentative)
```

---

## 13. FORMULES ESSENTIELLES Ã€ MÃ‰MORISER

### Erreur Standard
```
SE = s / âˆšn
```

### Intervalles de Confiance
```
IC 95% (moyenne) = xÌ„ Â± 1.96 Ã— (s/âˆšn)
IC 95% (proportion) = pÌ‚ Â± 1.96 Ã— âˆš[pÌ‚(1-pÌ‚)/n]
```

### Taille d'Ã‰chantillon (Proportion)
```
n = ZÂ² Ã— p(1-p) / EÂ²

Pour 95% confiance, E=3%, p=0.5:
n = (1.96)Â² Ã— 0.25 / (0.03)Â² â‰ˆ 1067
```

### Test t
```
t = (xÌ„ - Î¼â‚€) / (s/âˆšn)
df = n - 1
```

### Test Z (Proportion)
```
Z = (pÌ‚ - pâ‚€) / âˆš[pâ‚€(1-pâ‚€)/n]
```

### Chi-CarrÃ©
```
Ï‡Â² = Î£[(O - E)Â² / E]
df = (lignes-1) Ã— (colonnes-1)
```

### CorrÃ©lation Pearson
```
r = Î£[(x-xÌ„)(y-È³)] / âˆš[Î£(x-xÌ„)Â² Ã— Î£(y-È³)Â²]
```

### Cohen's d (Taille d'effet)
```
d = (xÌ„â‚ - xÌ„â‚‚) / s_pooled

InterprÃ©tation:
d < 0.2: Faible
0.2 â‰¤ d < 0.8: ModÃ©rÃ©
d â‰¥ 0.8: Fort
```

---

## 14. CHECKLIST EXAMEN

### Avant de RÃ©pondre
â˜ Identifier le TYPE de variables (continue, catÃ©gorielle, ordinale)  
â˜ Identifier le NOMBRE de groupes Ã  comparer  
â˜ VÃ©rifier si donnÃ©es APPARIÃ‰ES ou INDÃ‰PENDANTES  
â˜ Choisir le TEST appropriÃ© (voir arbres de dÃ©cision)

### Pendant le Test Statistique
â˜ Formuler clairement Hâ‚€ et Hâ‚  
â˜ Choisir Î± (gÃ©nÃ©ralement 0.05)  
â˜ VÃ©rifier CONDITIONS d'application  
â˜ Calculer CORRECTEMENT la statistique  
â˜ Comparer Ã  valeur critique OU interprÃ©ter p-value  
â˜ Prendre DÃ‰CISION (rejeter ou garder Hâ‚€)

### InterprÃ©tation Business
â˜ Traduire rÃ©sultat statistique en LANGAGE BUSINESS  
â˜ Ã‰valuer TAILLE D'EFFET (pas juste significativitÃ©)  
â˜ Mentionner LIMITATIONS  
â˜ Proposer ACTIONS concrÃ¨tes

---

## 15. DERNIERS CONSEILS

### Pour l'Examen Ã‰crit

1. **Ã‰crire proprement**: Les formules doivent Ãªtre LISIBLES
2. **Montrer les Ã©tapes**: MÃªme si calcul simple, montrer le raisonnement
3. **UnitÃ©s**: TOUJOURS inclure les unitÃ©s (HTG, %, etc.)
4. **Arrondir intelligemment**: 2 dÃ©cimales pour statistiques, 4 pour p-values
5. **Conclusion en franÃ§ais**: Toujours conclure en langage clair

### Gestion du Temps

- **Lire TOUTES les questions d'abord** (5 min)
- **Commencer par questions faciles** (confiance)
- **Allouer temps proportionnel aux points**
- **Garder 10 min Ã  la fin pour relecture**

### Si Blocage

1. Passer Ã  question suivante
2. Revenir aprÃ¨s
3. Ã‰crire ce que vous savez (points partiels!)
4. Justifier vos choix mÃªme si incertain

---

**BONNE CHANCE ALEXANDRO! ğŸš€**

Tu as tout ce qu'il faut pour RÃ‰USSIR! ğŸ’ª
